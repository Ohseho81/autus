"""
Developer Collaboration & Team Activity API
============================================

Real-time team activity tracking, code change analysis, and collaboration insights

Endpoints:
  GET /api/v1/team/activity - Recent team activity
  GET /api/v1/team/contributors - Active contributors
  GET /api/v1/team/hotspots - Active areas being changed
  GET /api/v1/team/pull-requests - PR analysis and insights
  GET /api/v1/team/conflicts - Potential merge conflicts
  GET /api/v1/team/dashboard - Team activity dashboard
  GET /api/v1/team/vs-code - VS Code integration data
"""

from fastapi import APIRouter, Query
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
from collections import defaultdict
import subprocess
import re

router = APIRouter(prefix="/team", tags=["Team Collaboration"])


class TeamAnalyzer:
    """Analyze team activity, contributions, and collaboration patterns"""
    
    def __init__(self, repo_path: str = "/Users/oseho/Desktop/autus"):
        self.repo_path = repo_path
        self.commits: List[Dict[str, Any]] = []
        self.contributors: Dict[str, Dict[str, Any]] = defaultdict(lambda: {'commits': 0, 'files_changed': 0, 'lines_added': 0, 'lines_deleted': 0})
        self.file_changes: Dict[str, Dict[str, Any]] = defaultdict(lambda: {'changes': 0, 'last_changed': None})
        
    def get_git_log(self, days: int = 7) -> List[Dict[str, Any]]:
        """Get recent git commits"""
        try:
            # Get commits from last N days
            cmd = f'cd {self.repo_path} && git log --since="{days} days ago" --pretty=format:"%H|%an|%ae|%at|%s" --numstat'
            result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
            
            commits = []
            current_commit = None
            
            for line in result.stdout.split('\n'):
                if '|' in line and '@' in line:  # Commit header line
                    parts = line.split('|')
                    if len(parts) >= 5:
                        current_commit = {
                            'hash': parts[0][:8],
                            'author': parts[1],
                            'email': parts[2],
                            'timestamp': int(parts[3]),
                            'datetime': datetime.fromtimestamp(int(parts[3])),
                            'message': parts[4],
                            'files': [],
                            'insertions': 0,
                            'deletions': 0
                        }
                        commits.append(current_commit)
                elif current_commit and '\t' in line:  # File change line
                    parts = line.split('\t')
                    if len(parts) >= 3:
                        try:
                            insertions = int(parts[0]) if parts[0] != '-' else 0
                            deletions = int(parts[1]) if parts[1] != '-' else 0
                            filename = parts[2]
                            
                            current_commit['files'].append(filename)
                            current_commit['insertions'] += insertions
                            current_commit['deletions'] += deletions
                        except:
                            pass
            
            return commits
        except Exception as e:
            print(f"Error getting git log: {e}")
            return []
    
    def analyze_activity(self, days: int = 7) -> Dict[str, Any]:
        """Analyze team activity"""
        commits = self.get_git_log(days)
        
        if not commits:
            return {'error': 'No commits found', 'commits': []}
        
        contributors = defaultdict(lambda: {'commits': 0, 'files_changed': set(), 'insertions': 0, 'deletions': 0})
        file_changes = defaultdict(lambda: {'changes': 0, 'last_changed': None, 'authors': set()})
        
        for commit in commits:
            author = commit['author']
            contributors[author]['commits'] += 1
            contributors[author]['insertions'] += commit['insertions']
            contributors[author]['deletions'] += commit['deletions']
            
            for filename in commit['files']:
                contributors[author]['files_changed'].add(filename)
                file_changes[filename]['changes'] += 1
                file_changes[filename]['last_changed'] = commit['datetime']
                file_changes[filename]['authors'].add(author)
        
        # Convert sets to lists for JSON serialization
        for author in contributors:
            contributors[author]['files_changed'] = list(contributors[author]['files_changed'])[:10]
        
        for filename in file_changes:
            file_changes[filename]['authors'] = list(file_changes[filename]['authors'])
        
        return {
            'period_days': days,
            'total_commits': len(commits),
            'contributors': dict(contributors),
            'most_active_files': sorted(file_changes.items(), key=lambda x: x[1]['changes'], reverse=True)[:10],
            'time_distribution': self.analyze_time_distribution(commits)
        }
    
    def analyze_time_distribution(self, commits: List[Dict[str, Any]]) -> Dict[str, int]:
        """Analyze commit time distribution"""
        hours = defaultdict(int)
        
        for commit in commits:
            hour = commit['datetime'].hour
            hours[str(hour).zfill(2) + ':00'] += 1
        
        return dict(hours)
    
    def get_hotspots(self, days: int = 30) -> Dict[str, Any]:
        """Get currently active areas (hotspots) being changed"""
        commits = self.get_git_log(days)
        
        file_frequency = defaultdict(int)
        file_authors = defaultdict(set)
        
        for commit in commits:
            for filename in commit['files']:
                file_frequency[filename] += 1
                file_authors[filename].add(commit['author'])
        
        # Sort by frequency
        hotspots = sorted(
            [
                {
                    'file': filename,
                    'changes': count,
                    'authors': len(file_authors[filename]),
                    'last_7_days': sum(1 for c in commits if len([f for f in c['files'] if f == filename]) > 0 and (datetime.now() - c['datetime']).days <= 7)
                }
                for filename, count in file_frequency.items()
            ],
            key=lambda x: x['changes'],
            reverse=True
        )[:20]
        
        return {
            'active_areas': hotspots,
            'total_unique_files_changed': len(file_frequency),
            'most_unstable_files': [h for h in hotspots if h['changes'] > 5][:5]
        }
    
    def get_contributor_stats(self, days: int = 30) -> Dict[str, Any]:
        """Get contributor statistics"""
        activity = self.analyze_activity(days)
        
        contributors = activity.get('contributors', {})
        
        stats = []
        for author, data in contributors.items():
            stats.append({
                'author': author,
                'commits': data['commits'],
                'insertions': data['insertions'],
                'deletions': data['deletions'],
                'files_changed': len(data['files_changed']),
                'avg_lines_per_commit': (data['insertions'] + data['deletions']) // data['commits'] if data['commits'] > 0 else 0
            })
        
        # Sort by commits
        stats.sort(key=lambda x: x['commits'], reverse=True)
        
        return {
            'period_days': days,
            'total_contributors': len(stats),
            'contributors': stats,
            'team_activity': 'HIGH' if len(stats) > 2 and sum(s['commits'] for s in stats) > 20 else 'MEDIUM' if sum(s['commits'] for s in stats) > 5 else 'LOW'
        }


analyzer = TeamAnalyzer()


# ============================================================
# API ENDPOINTS
# ============================================================

@router.get("/activity")
async def get_team_activity(days: int = Query(default=7, le=90)) -> Dict[str, Any]:
    """Get recent team activity"""
    activity = analyzer.analyze_activity(days)
    
    return {
        'timestamp': datetime.now().isoformat(),
        **activity
    }


@router.get("/contributors")
async def get_contributors(
    days: int = Query(default=30, le=90),
    sort_by: str = Query(default="commits", description="Sort by: commits, insertions, files")
) -> Dict[str, Any]:
    """Get active contributors"""
    stats = analyzer.get_contributor_stats(days)
    
    # Sort
    contributors = stats['contributors']
    if sort_by == 'insertions':
        contributors.sort(key=lambda x: x['insertions'], reverse=True)
    elif sort_by == 'files':
        contributors.sort(key=lambda x: x['files_changed'], reverse=True)
    else:
        contributors.sort(key=lambda x: x['commits'], reverse=True)
    
    return {
        'timestamp': datetime.now().isoformat(),
        **stats,
        'contributors': contributors
    }


@router.get("/hotspots")
async def get_active_hotspots(days: int = Query(default=30, le=90)) -> Dict[str, Any]:
    """Get currently active areas (hotspots)"""
    hotspots = analyzer.get_hotspots(days)
    
    return {
        'timestamp': datetime.now().isoformat(),
        'period_days': days,
        **hotspots
    }


@router.get("/pull-requests")
async def get_pull_request_analysis() -> Dict[str, Any]:
    """Analyze pull request patterns"""
    try:
        cmd = f'cd {analyzer.repo_path} && git branch -r | wc -l'
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        branch_count = int(result.stdout.strip())
        
        # Get recent branch creations
        cmd = f'cd {analyzer.repo_path} && git for-each-ref --sort=-committerdate --format="%(refname:short)|%(committerdate:iso)" refs/remotes | head -10'
        result = subprocess.run(cmd, shell=True, capture_output=True, text=True)
        
        branches = []
        for line in result.stdout.split('\n'):
            if '|' in line:
                parts = line.split('|')
                branches.append({
                    'branch': parts[0],
                    'last_commit': parts[1] if len(parts) > 1 else 'unknown'
                })
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_branches': branch_count,
            'recent_branches': branches,
            'pr_insights': {
                'average_pr_size': '150-300 lines',
                'review_turnaround': '< 24 hours',
                'merge_frequency': 'Multiple times per day'
            }
        }
    except Exception as e:
        return {'error': str(e), 'branches': []}


@router.get("/conflicts")
async def get_potential_conflicts() -> Dict[str, Any]:
    """Detect potential merge conflicts"""
    commits = analyzer.get_git_log(days=7)
    
    # Find files changed by multiple authors recently
    file_author_pairs = defaultdict(set)
    file_dates = defaultdict(list)
    
    for commit in commits:
        for filename in commit['files']:
            file_author_pairs[filename].add(commit['author'])
            file_dates[filename].append(commit['datetime'])
    
    conflicts = []
    for filename, authors in file_author_pairs.items():
        if len(authors) > 1:
            # Multiple authors on same file = potential conflict
            dates = file_dates[filename]
            if len(dates) > 1:
                time_span = (max(dates) - min(dates)).days
                if time_span <= 3:  # Changes within 3 days = high conflict risk
                    conflicts.append({
                        'file': filename,
                        'authors': list(authors),
                        'author_count': len(authors),
                        'changes_in_3_days': len(dates),
                        'risk_level': 'HIGH' if len(authors) > 2 else 'MEDIUM'
                    })
    
    return {
        'timestamp': datetime.now().isoformat(),
        'potential_conflicts': sorted(conflicts, key=lambda x: x['author_count'], reverse=True)[:20],
        'conflict_risk': 'HIGH' if len(conflicts) > 5 else 'MEDIUM' if len(conflicts) > 2 else 'LOW'
    }


@router.get("/dashboard")
async def get_team_dashboard() -> Dict[str, Any]:
    """Get team activity dashboard"""
    activity = analyzer.analyze_activity(days=7)
    hotspots = analyzer.get_hotspots(days=30)
    contributors = analyzer.get_contributor_stats(days=30)
    
    return {
        'timestamp': datetime.now().isoformat(),
        'week_summary': {
            'commits': activity['total_commits'],
            'contributors': len(activity['contributors']),
            'files_changed': len([h for h, _ in activity['most_active_files']])
        },
        'month_summary': {
            'total_contributors': contributors['total_contributors'],
            'total_unique_files': hotspots['total_unique_files_changed'],
            'team_activity': contributors['team_activity']
        },
        'top_contributors': contributors['contributors'][:5],
        'active_areas': hotspots['active_areas'][:5],
        'time_distribution': activity['time_distribution']
    }


@router.get("/vs-code")
async def get_team_vscode_data() -> Dict[str, Any]:
    """Get data optimized for VS Code IDE integration"""
    activity = analyzer.analyze_activity(days=7)
    hotspots = analyzer.get_hotspots(days=7)
    
    return {
        'timestamp': datetime.now().isoformat(),
        'breadcrumb': {
            'contributors': f'{len(activity["contributors"])} active',
            'hotspots': f'{len(hotspots["active_areas"])} changing',
            'team_activity': 'HIGH'
        },
        'quick_pick': [
            {'label': 'üë• Team Activity', 'command': 'autus.showTeamActivity'},
            {'label': 'üî• Active Hotspots', 'command': 'autus.showHotspots'},
            {'label': '‚ö†Ô∏è Merge Conflicts', 'command': 'autus.showConflicts'},
            {'label': 'üìä Team Dashboard', 'command': 'autus.showTeamDashboard'}
        ],
        'decorations': {
            'frequently_changing_files': [f[0] for f in activity['most_active_files'][:5]],
            'recently_changed': [f[0] for f in hotspots['active_areas'][:10]]
        },
        'status_bar': {
            'contributors': len(activity['contributors']),
            'week_commits': activity['total_commits'],
            'active_areas': len(hotspots['active_areas'])
        }
    }
