#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }















#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ”„ AUTUS v3.0 - 6 Automation Loops                                     â•‘
â•‘                                                                                           â•‘
â•‘  Layer 3: 6ê°€ì§€ ìë™í™” ë£¨í”„ ì—”ì§„                                                            â•‘
â•‘                                                                                           â•‘
â•‘  Loop 1: Auto Collect   - ë°ì´í„° ìë™ ìˆ˜ì§‘                                                 â•‘
â•‘  Loop 2: Auto Learn     - LLM ê¸°ë°˜ í•™ìŠµ                                                    â•‘
â•‘  Loop 3: Auto Delete    - ì €í’ˆì§ˆ ë°ì´í„° ì •ë¦¬                                               â•‘
â•‘  Loop 4: Auto Improve   - Reflexion ê¸°ë°˜ ê°œì„                                               â•‘
â•‘  Loop 5: Auto Execute   - Multi-Agent ì‹¤í–‰                                                 â•‘
â•‘  Loop 6: Auto Loop      - Flywheel ìˆœí™˜                                                    â•‘
â•‘                                                                                           â•‘
â•‘  âš ï¸ v1.3 PIPELINE LOCK ì˜í–¥ ì—†ìŒ - í˜¸ì¶œë§Œ í•¨                                               â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import uuid
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional, Tuple
import pandas as pd

from .database import get_database, DatabaseManager
from .db_schema import (
    MoneyEvent, BurnEvent, Insight, Archive, Proposal, FlywheelCycle, AgentLog,
    ProposalStatus
)
from .quality import QualityManager, validate_money_event, validate_burn_event


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 1: Auto Collect (ìë™ ìˆ˜ì§‘)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoCollectLoop:
    """
    Loop 1: ë°ì´í„° ìë™ ìˆ˜ì§‘
    
    - Webhook/APIë¡œ ë“¤ì–´ì˜¤ëŠ” ì´ë²¤íŠ¸ ê²€ì¦ ë° ì €ì¥
    - Schema ê²€ì¦ 100% í†µê³¼ í•„ìˆ˜
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def collect_money_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Money ì´ë²¤íŠ¸ ìˆ˜ì§‘
        
        Returns:
            (success, message)
        """
        # í’ˆì§ˆ ê²€ì¦
        result = self.quality.validate_money_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        # DB ì €ì¥
        event = MoneyEvent(
            event_id=data.get("event_id") or f"M-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            event_type=data["event_type"],
            currency=data["currency"],
            amount=float(data["amount"]),
            people_tags=data["people_tags"],
            effective_minutes=int(data["effective_minutes"]),
            evidence_id=data["evidence_id"],
            recommendation_type=data["recommendation_type"],
            customer_id=data["customer_id"],
            project_id=data.get("project_id"),
            amount_krw=data.get("amount_krw"),
            processed=False,
        )
        
        event_id = self.db.insert_money_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {event_id}"
    
    def collect_burn_event(self, data: Dict[str, Any]) -> Tuple[bool, str]:
        """
        Burn ì´ë²¤íŠ¸ ìˆ˜ì§‘
        """
        result = self.quality.validate_burn_event(data)
        
        if not result.is_valid:
            return False, f"ê²€ì¦ ì‹¤íŒ¨: {result.schema_errors}"
        
        event = BurnEvent(
            burn_id=data.get("burn_id") or f"B-{uuid.uuid4().hex[:8]}",
            date=data["date"],
            burn_type=data["burn_type"],
            loss_minutes=int(data["loss_minutes"]),
            evidence_id=data["evidence_id"],
            person_or_edge=data.get("person_or_edge"),
            prevented_by=data.get("prevented_by"),
            prevented_minutes=data.get("prevented_minutes"),
            processed=False,
        )
        
        burn_id = self.db.insert_burn_event(event)
        return True, f"ì €ì¥ ì™„ë£Œ: {burn_id}"
    
    def collect_from_webhook(self, payload: Dict[str, Any]) -> Dict[str, Any]:
        """
        Webhook í˜ì´ë¡œë“œ ì²˜ë¦¬
        """
        event_type = payload.get("type", "").upper()
        data = payload.get("data", {})
        
        if event_type == "MONEY":
            success, message = self.collect_money_event(data)
        elif event_type == "BURN":
            success, message = self.collect_burn_event(data)
        else:
            return {"success": False, "message": f"Unknown type: {event_type}"}
        
        return {"success": success, "message": message}
    
    def get_unprocessed_count(self) -> Dict[str, int]:
        """ë¯¸ì²˜ë¦¬ ì´ë²¤íŠ¸ ìˆ˜"""
        return {
            "money": len(self.db.get_unprocessed_money_events()),
            "burn": len(self.db.get_unprocessed_burn_events()),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 2: Auto Learn (ìë™ í•™ìŠµ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLearnLoop:
    """
    Loop 2: LLM ê¸°ë°˜ ìë™ í•™ìŠµ
    
    - PIPELINE ê²°ê³¼ì—ì„œ íŒ¨í„´ ë¶„ì„
    - ì¸ì‚¬ì´íŠ¸ ìƒì„± ë° ì €ì¥
    - Confidence > 0.7 í•„í„°ë§
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.api_key = os.getenv("ANTHROPIC_API_KEY") or os.getenv("OPENAI_API_KEY")
    
    def analyze_pipeline_result(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        PIPELINE ê²°ê³¼ ë¶„ì„
        """
        insights = []
        kpi = result.get("kpi", {})
        
        # íŒ¨í„´ 1: ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.25:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="ANOMALY",
                content=f"Entropy {entropy:.0%}ë¡œ ë†’ìŒ. ì†ì‹¤ ìš”ì¸ ì§‘ì¤‘ ë¶„ì„ í•„ìš”.",
                confidence=0.85,
            )
            insights.append(insight)
        
        # íŒ¨í„´ 2: ë‚®ì€ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0:
            roi = net / mint
            if roi < 0.5:
                insight = self._create_insight(
                    week_id=week_id,
                    source="PIPELINE",
                    category="PATTERN",
                    content=f"ROI {roi:.0%}ë¡œ ë‚®ìŒ. ìˆ˜ìµì„± ê°œì„  í•„ìš”.",
                    confidence=0.80,
                )
                insights.append(insight)
        
        # íŒ¨í„´ 3: íŒ€ ì‹œë„ˆì§€ ë¶„ì„
        best_team = result.get("best_team", {})
        team_score = best_team.get("score", 0)
        if team_score > 0:
            insight = self._create_insight(
                week_id=week_id,
                source="PIPELINE",
                category="RECOMMENDATION",
                content=f"ìµœì  íŒ€ ì ìˆ˜: {team_score:,.0f}. íŒ€ êµ¬ì„± ìœ ì§€ ê¶Œì¥.",
                confidence=0.75,
            )
            insights.append(insight)
        
        return insights
    
    def analyze_pillars_result(self, pillars: Dict[str, Any], week_id: str) -> List[Insight]:
        """
        5 Pillars ê²°ê³¼ ë¶„ì„
        """
        insights = []
        summary = pillars.get("summary", {})
        
        # ì•½ì  ê¸°ë‘¥ ë¶„ì„
        weakest = summary.get("weakest_pillar", "")
        weakest_score = summary.get("weakest_score", 0)
        
        if weakest and weakest_score < 0.4:
            pillar_names = {
                "vision_mastery": "ë¹„ì „ ì¥ì•…",
                "risk_equilibrium": "ìœ„í—˜ ê· í˜•",
                "innovation_disruption": "í˜ì‹  ì£¼ë„",
                "learning_acceleration": "í•™ìŠµ ê°€ì†",
                "impact_amplification": "ì˜í–¥ ì¦í­",
            }
            name = pillar_names.get(weakest, weakest)
            
            insight = self._create_insight(
                week_id=week_id,
                source="PILLARS",
                category="RECOMMENDATION",
                content=f"'{name}' ê¸°ë‘¥ì´ {weakest_score:.0%}ë¡œ ê°€ì¥ ì•½í•¨. ì§‘ì¤‘ ê°•í™” í•„ìš”.",
                confidence=0.90,
            )
            insights.append(insight)
        
        return insights
    
    def learn_from_pipeline_result(self, result: Dict[str, Any], week_id: str) -> int:
        """
        PIPELINE ê²°ê³¼ì—ì„œ í•™ìŠµí•˜ê³  ì¸ì‚¬ì´íŠ¸ ì €ì¥
        
        Returns:
            ì €ì¥ëœ ì¸ì‚¬ì´íŠ¸ ìˆ˜
        """
        all_insights = []
        
        # PIPELINE ë¶„ì„
        if "kpi" in result:
            all_insights.extend(self.analyze_pipeline_result(result, week_id))
        
        # Pillars ë¶„ì„
        if "pillars" in result:
            all_insights.extend(self.analyze_pillars_result(result["pillars"], week_id))
        
        # LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„ (API ìˆì„ ë•Œ)
        if self.api_key:
            llm_insights = self._llm_analyze(result, week_id)
            all_insights.extend(llm_insights)
        
        # ì €ì¥ (Confidence > 0.7ë§Œ)
        saved_count = 0
        for insight in all_insights:
            if insight.confidence >= 0.7:
                self.db.insert_insight(insight)
                saved_count += 1
        
        return saved_count
    
    def _create_insight(
        self,
        week_id: str,
        source: str,
        category: str,
        content: str,
        confidence: float,
        metadata: Dict = None
    ) -> Insight:
        """ì¸ì‚¬ì´íŠ¸ ê°ì²´ ìƒì„±"""
        return Insight(
            insight_id=f"I-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            source=source,
            category=category,
            content=content,
            confidence=confidence,
            metadata=json.dumps(metadata or {}),
        )
    
    def _llm_analyze(self, result: Dict[str, Any], week_id: str) -> List[Insight]:
        """LLM ê¸°ë°˜ ì‹¬ì¸µ ë¶„ì„"""
        insights = []
        
        # Mock ë˜ëŠ” ì‹¤ì œ LLM í˜¸ì¶œ
        kpi = result.get("kpi", {})
        prompt = f"""AUTUS ì£¼ê°„ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ì¸ì‚¬ì´íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

KPI:
- Net: {kpi.get('net_krw', 0):,.0f} ì›
- Mint: {kpi.get('mint_krw', 0):,.0f} ì›
- Burn: {kpi.get('burn_krw', 0):,.0f} ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}

ê°€ì¥ ì¤‘ìš”í•œ ì¸ì‚¬ì´íŠ¸ 1ê°œë¥¼ í•œ ë¬¸ì¥ìœ¼ë¡œ ì œê³µí•´ì£¼ì„¸ìš”."""

        try:
            content = self._call_llm(prompt)
            if content:
                insight = self._create_insight(
                    week_id=week_id,
                    source="LLM",
                    category="PATTERN",
                    content=content,
                    confidence=0.75,
                )
                insights.append(insight)
        except Exception as e:
            pass  # LLM ì‹¤íŒ¨ ì‹œ ë¬´ì‹œ
        
        return insights
    
    def _call_llm(self, prompt: str) -> str:
        """LLM í˜¸ì¶œ"""
        if os.getenv("ANTHROPIC_API_KEY"):
            try:
                import anthropic
                client = anthropic.Anthropic()
                response = client.messages.create(
                    model="claude-3-haiku-20240307",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.content[0].text
            except:
                pass
        
        if os.getenv("OPENAI_API_KEY"):
            try:
                import openai
                client = openai.OpenAI()
                response = client.chat.completions.create(
                    model="gpt-4o-mini",
                    max_tokens=200,
                    messages=[{"role": "user", "content": prompt}]
                )
                return response.choices[0].message.content
            except:
                pass
        
        return ""


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 3: Auto Delete (ìë™ ì‚­ì œ/ì •ë¦¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoDeleteLoop:
    """
    Loop 3: ì €í’ˆì§ˆ ë°ì´í„° ìë™ ì •ë¦¬
    
    - Quality < 0.3 ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - 90ì¼ ë¯¸í™œë™ ë°ì´í„° ì•„ì¹´ì´ë¸Œ
    - LLMìœ¼ë¡œ ìš”ì•½ ìƒì„± í›„ ì›ë³¸ ì‚­ì œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.quality = QualityManager()
    
    def find_low_quality_insights(self, threshold: float = 0.3) -> List[Dict]:
        """ë‚®ì€ í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì°¾ê¸°"""
        # ëª¨ë“  ì¸ì‚¬ì´íŠ¸ ì¡°íšŒ í›„ í•„í„°ë§
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            cursor.execute("SELECT * FROM insights WHERE confidence < ?", (threshold,))
            rows = cursor.fetchall()
            return [dict(row) for row in rows]
    
    def find_inactive_data(self, days: int = 90) -> Dict[str, List]:
        """ë¹„í™œì„± ë°ì´í„° ì°¾ê¸°"""
        cutoff = (datetime.now() - timedelta(days=days)).isoformat()
        inactive = {"insights": [], "agent_logs": []}
        
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            
            # ì˜¤ë˜ëœ ì¸ì‚¬ì´íŠ¸
            cursor.execute(
                "SELECT * FROM insights WHERE created_at < ?",
                (cutoff,)
            )
            inactive["insights"] = [dict(row) for row in cursor.fetchall()]
            
            # ì˜¤ë˜ëœ ë¡œê·¸
            cursor.execute(
                "SELECT * FROM agent_logs WHERE created_at < ?",
                (cutoff,)
            )
            inactive["agent_logs"] = [dict(row) for row in cursor.fetchall()]
        
        return inactive
    
    def archive_and_delete(self, item_type: str, item_id: str, item_data: Dict, reason: str) -> str:
        """ì•„ì¹´ì´ë¸Œ í›„ ì‚­ì œ"""
        # ìš”ì•½ ìƒì„±
        summary = self._generate_summary(item_data)
        
        # ì•„ì¹´ì´ë¸Œ ì €ì¥
        archive = Archive(
            archive_id=f"A-{uuid.uuid4().hex[:8]}",
            original_type=item_type,
            original_id=item_id,
            summary=summary,
            reason=reason,
            original_data=json.dumps(item_data, ensure_ascii=False),
        )
        self.db.insert_archive(archive)
        
        # ì›ë³¸ ì‚­ì œ
        with self.db._get_connection() as conn:
            cursor = conn.cursor()
            table_map = {
                "INSIGHT": "insights",
                "AGENT_LOG": "agent_logs",
            }
            table = table_map.get(item_type)
            if table:
                id_col = "insight_id" if item_type == "INSIGHT" else "log_id"
                cursor.execute(f"DELETE FROM {table} WHERE {id_col} = ?", (item_id,))
                conn.commit()
        
        return archive.archive_id
    
    def cleanup_cycle(self) -> Dict[str, int]:
        """ì •ë¦¬ ì‚¬ì´í´ ì‹¤í–‰"""
        results = {"archived": 0, "skipped": 0}
        
        # ì €í’ˆì§ˆ ì¸ì‚¬ì´íŠ¸ ì •ë¦¬
        low_quality = self.find_low_quality_insights()
        for item in low_quality:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "LOW_QUALITY"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        # ë¹„í™œì„± ë°ì´í„° ì •ë¦¬ (90ì¼)
        inactive = self.find_inactive_data(90)
        for item in inactive["insights"]:
            try:
                self.archive_and_delete(
                    "INSIGHT",
                    item["insight_id"],
                    item,
                    "INACTIVE"
                )
                results["archived"] += 1
            except:
                results["skipped"] += 1
        
        return results
    
    def _generate_summary(self, data: Dict) -> str:
        """LLMìœ¼ë¡œ ìš”ì•½ ìƒì„±"""
        # Mock ìš”ì•½
        if "content" in data:
            return f"ìš”ì•½: {data['content'][:100]}..."
        return f"ìš”ì•½: {json.dumps(data, ensure_ascii=False)[:100]}..."


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 4: Auto Improve (Reflexion ê¸°ë°˜ ê°œì„ )
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoImproveLoop:
    """
    Loop 4: Reflexion ê¸°ë°˜ ìë™ ê°œì„ 
    
    - ì‹¤íŒ¨ ê°ì§€ (Entropy > 30%, ROI < 0)
    - "ì™œ ì‹¤íŒ¨í–ˆë‚˜?" ë¶„ì„
    - ê°œì„  ì œì•ˆ ìƒì„±
    - Human-in-the-Loop ìŠ¹ì¸ ëŒ€ê¸°
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
    
    def check_failures(self, kpi: Dict) -> List[Dict]:
        """ì‹¤íŒ¨ ì¡°ê±´ ê²€ì‚¬"""
        failures = []
        
        # ë†’ì€ Entropy
        entropy = kpi.get("entropy_ratio", 0)
        if entropy > 0.30:
            failures.append({
                "trigger": "HIGH_ENTROPY",
                "value": entropy,
                "threshold": 0.30,
                "severity": "HIGH" if entropy > 0.40 else "MEDIUM",
            })
        
        # ìŒìˆ˜ ROI
        mint = kpi.get("mint_krw", 0)
        net = kpi.get("net_krw", 0)
        if mint > 0 and net < 0:
            failures.append({
                "trigger": "NEGATIVE_ROI",
                "value": net / mint,
                "threshold": 0,
                "severity": "HIGH",
            })
        
        # ë‚®ì€ Velocity
        velocity = kpi.get("velocity", 0)
        if velocity < 0.3:
            failures.append({
                "trigger": "LOW_VELOCITY",
                "value": velocity,
                "threshold": 0.30,
                "severity": "MEDIUM",
            })
        
        return failures
    
    def generate_reflexion(self, failure: Dict, kpi: Dict, week_id: str) -> Proposal:
        """
        Reflexion ë¶„ì„ ë° ì œì•ˆ ìƒì„±
        """
        trigger = failure["trigger"]
        value = failure["value"]
        
        # ë¶„ì„ ìƒì„±
        if trigger == "HIGH_ENTROPY":
            analysis = f"Entropy {value:.1%}ë¡œ ì†ì‹¤ ë¹„ìœ¨ì´ ë†’ìŒ. ì£¼ìš” ì†ì‹¤ ìš”ì¸ ë¶„ì„ í•„ìš”."
            suggestion = "1. Burn ì´ë²¤íŠ¸ ìƒì„¸ ë¶„ì„\n2. DELAY/REWORK ìœ í˜• ì§‘ì¤‘ ê²€í† \n3. í”„ë¡œì„¸ìŠ¤ ë³‘ëª© ì œê±°"
            impact = f"Entropy 10%p ê°ì†Œ â†’ Net {kpi.get('burn_krw', 0) * 0.1:,.0f}ì› ì ˆê° ì˜ˆìƒ"
        
        elif trigger == "NEGATIVE_ROI":
            analysis = f"ROI {value:.1%}ë¡œ ì†ì‹¤ ìƒíƒœ. ìˆ˜ìµ êµ¬ì¡° ì¬ê²€í†  í•„ìš”."
            suggestion = "1. ê³ ìˆ˜ìµ ì´ë²¤íŠ¸ íƒ€ì… í™•ëŒ€\n2. ì €ìˆ˜ìµ í”„ë¡œì íŠ¸ ì¶•ì†Œ\n3. ë¹„ìš© êµ¬ì¡° ìµœì í™”"
            impact = "ROI 20%p ê°œì„  ëª©í‘œ"
        
        elif trigger == "LOW_VELOCITY":
            analysis = f"Flywheel Velocity {value:.1%}ë¡œ ìˆœí™˜ ëŠë¦¼. ì¬íˆ¬ì ë¹„ìœ¨ ì ê²€ í•„ìš”."
            suggestion = "1. REINVEST ë‹¨ê³„ ê°•í™”\n2. GROW ë‹¨ê³„ í™œì„±í™”\n3. ë³‘ëª© ë‹¨ê³„ ì‹ë³„"
            impact = "Velocity 15%p ìƒìŠ¹ ëª©í‘œ"
        
        else:
            analysis = f"{trigger} ë¬¸ì œ ê°ì§€. ìƒì„¸ ë¶„ì„ í•„ìš”."
            suggestion = "ë°ì´í„° ê¸°ë°˜ ë¶„ì„ í›„ ì œì•ˆ ì˜ˆì •"
            impact = "ê°œì„  íš¨ê³¼ ì¸¡ì • ì˜ˆì •"
        
        return Proposal(
            proposal_id=f"P-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            trigger=trigger,
            analysis=analysis,
            suggestion=suggestion,
            expected_impact=impact,
            status=ProposalStatus.PENDING.value,
        )
    
    def run_improvement_cycle(self, kpi: Dict, week_id: str) -> List[str]:
        """ê°œì„  ì‚¬ì´í´ ì‹¤í–‰"""
        proposal_ids = []
        
        failures = self.check_failures(kpi)
        
        for failure in failures:
            proposal = self.generate_reflexion(failure, kpi, week_id)
            self.db.insert_proposal(proposal)
            proposal_ids.append(proposal.proposal_id)
        
        return proposal_ids
    
    def get_pending_proposals(self) -> List[Dict]:
        """ëŒ€ê¸° ì¤‘ì¸ ì œì•ˆ ì¡°íšŒ"""
        proposals = self.db.get_pending_proposals()
        return [p.to_dict() for p in proposals]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 5: Auto Execute (Multi-Agent ì‹¤í–‰)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoExecuteLoop:
    """
    Loop 5: Multi-Agent ìë™ ì‹¤í–‰
    
    - CrewAI ë˜ëŠ” Built-in Agents ì‚¬ìš©
    - Researcher â†’ Analyzer â†’ Executor â†’ Reporter ìˆœì„œ
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        
        # CrewAI ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        try:
            from .crew import AutusCrew
            self.crew = AutusCrew()
            self.crew_enabled = True
        except ImportError:
            self.crew = None
            self.crew_enabled = False
    
    def run_weekly_crew(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """ì£¼ê°„ í¬ë£¨ ì‹¤í–‰"""
        if self.crew_enabled and self.crew:
            return self.crew.run_weekly_crew(result, week_id)
        else:
            return self._run_builtin_agents(result, week_id)
    
    def _run_builtin_agents(self, result: Dict[str, Any], week_id: str) -> Dict[str, Any]:
        """Built-in ì—ì´ì „íŠ¸ ì‹¤í–‰ (CrewAI ì—†ì„ ë•Œ)"""
        outputs = {}
        
        # Agent 1: Researcher (ë°ì´í„° ì¡°ì‚¬)
        outputs["researcher"] = self._agent_research(result)
        
        # Agent 2: Analyzer (ë¶„ì„)
        outputs["analyzer"] = self._agent_analyze(result)
        
        # Agent 3: Executor (ì‹¤í–‰)
        outputs["executor"] = self._agent_execute(result)
        
        # Agent 4: Reporter (ë¦¬í¬íŠ¸)
        outputs["reporter"] = self._agent_report(result, outputs)
        
        return {
            "week_id": week_id,
            "agents_run": 4,
            "outputs": outputs,
            "success": True,
        }
    
    def _agent_research(self, result: Dict) -> Dict:
        """Researcher Agent"""
        kpi = result.get("kpi", {})
        return {
            "role": "RESEARCHER",
            "task": "ë°ì´í„° ì¡°ì‚¬",
            "output": f"Net: {kpi.get('net_krw', 0):,.0f}ì›, íŒ€: {len(result.get('best_team', {}).get('team', []))}ëª…",
            "success": True,
        }
    
    def _agent_analyze(self, result: Dict) -> Dict:
        """Analyzer Agent"""
        kpi = result.get("kpi", {})
        entropy = kpi.get("entropy_ratio", 0)
        return {
            "role": "ANALYZER",
            "task": "PIPELINE ë¶„ì„",
            "output": f"Entropy: {entropy:.1%}, ìƒíƒœ: {'ì •ìƒ' if entropy < 0.25 else 'ì£¼ì˜'}",
            "success": True,
        }
    
    def _agent_execute(self, result: Dict) -> Dict:
        """Executor Agent"""
        return {
            "role": "EXECUTOR",
            "task": "ì•¡ì…˜ ì‹¤í–‰",
            "output": "ì•Œë¦¼ ë°œì†¡ ì™„ë£Œ, ë¦¬í¬íŠ¸ ìƒì„± ëŒ€ê¸°",
            "success": True,
        }
    
    def _agent_report(self, result: Dict, outputs: Dict) -> Dict:
        """Reporter Agent"""
        kpi = result.get("kpi", {})
        pillars = result.get("pillars", {}).get("summary", {})
        
        report = f"""## ì£¼ê°„ ìš”ì•½
- Net: {kpi.get('net_krw', 0):,.0f}ì›
- Entropy: {kpi.get('entropy_ratio', 0):.1%}
- Pillars ì ìˆ˜: {pillars.get('total_score', 0):.0%}
- ìƒíƒœ: {pillars.get('overall_status', 'N/A')}
"""
        return {
            "role": "REPORTER",
            "task": "ë¦¬í¬íŠ¸ ì‘ì„±",
            "output": report,
            "success": True,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Loop 6: Auto Loop (Flywheel ìˆœí™˜)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class AutoLoopEngine:
    """
    Loop 6: Flywheel ìë™ ìˆœí™˜
    
    - ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ê´€ë¦¬
    - Flywheel ì´ë ¥ ê´€ë¦¬
    - ROI ë° Velocity ì¶”ì 
    """
    
    def __init__(self, db: DatabaseManager = None):
        self.db = db or get_database()
        self.collect = AutoCollectLoop(self.db)
        self.learn = AutoLearnLoop(self.db)
        self.delete = AutoDeleteLoop(self.db)
        self.improve = AutoImproveLoop(self.db)
        self.execute = AutoExecuteLoop(self.db)
    
    def run_full_cycle(
        self,
        pipeline_result: Dict[str, Any],
        pillars_result: Dict[str, Any],
        week_id: str
    ) -> Dict[str, Any]:
        """ì „ì²´ 6 ë£¨í”„ ìˆœí™˜ ì‹¤í–‰"""
        cycle_result = {
            "week_id": week_id,
            "loops": {},
            "flywheel": {},
            "success": True,
        }
        
        # Loop 1: Collect (ì´ë¯¸ ì™„ë£Œëœ ë°ì´í„°)
        cycle_result["loops"]["collect"] = {
            "unprocessed": self.collect.get_unprocessed_count(),
        }
        
        # Loop 2: Learn
        insights_count = self.learn.learn_from_pipeline_result(
            {"kpi": pipeline_result.get("kpi", {}), "pillars": pillars_result},
            week_id
        )
        cycle_result["loops"]["learn"] = {
            "insights_generated": insights_count,
        }
        
        # Loop 3: Delete (ì›”ê°„ ì‹¤í–‰ ê¶Œì¥)
        # cleanup = self.delete.cleanup_cycle()
        cycle_result["loops"]["delete"] = {
            "archived": 0,  # ë§¤ì£¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŒ
        }
        
        # Loop 4: Improve
        kpi = pipeline_result.get("kpi", {})
        proposal_ids = self.improve.run_improvement_cycle(kpi, week_id)
        cycle_result["loops"]["improve"] = {
            "proposals_generated": len(proposal_ids),
            "proposal_ids": proposal_ids,
        }
        
        # Loop 5: Execute
        crew_result = self.execute.run_weekly_crew(
            {"kpi": kpi, "pillars": pillars_result, "best_team": pipeline_result.get("best_team", {})},
            week_id
        )
        cycle_result["loops"]["execute"] = {
            "agents_run": crew_result.get("agents_run", 0),
            "success": crew_result.get("success", False),
        }
        
        # Loop 6: Flywheel ì €ì¥
        flywheel_data = self._create_flywheel_cycle(pipeline_result, pillars_result, week_id)
        self.db.insert_flywheel_cycle(flywheel_data)
        
        cycle_result["flywheel"] = {
            "cycle_id": flywheel_data.cycle_id,
            "velocity": flywheel_data.velocity,
            "momentum": flywheel_data.momentum,
            "roi": flywheel_data.net_krw / flywheel_data.mint_krw if flywheel_data.mint_krw > 0 else 0,
        }
        
        return cycle_result
    
    def _create_flywheel_cycle(
        self,
        pipeline_result: Dict,
        pillars_result: Dict,
        week_id: str
    ) -> FlywheelCycle:
        """Flywheel ì‚¬ì´í´ ë°ì´í„° ìƒì„±"""
        kpi = pipeline_result.get("kpi", {})
        best_team = pipeline_result.get("best_team", {})
        summary = pillars_result.get("summary", {})
        scores = summary.get("pillar_scores", {})
        
        # Flywheel ìƒíƒœ ê³„ì‚°
        flywheel = pillars_result.get("vision_mastery", {}).get("flywheel", {})
        state = flywheel.get("state", {})
        score = flywheel.get("score", {})
        momentum = flywheel.get("momentum", {})
        
        return FlywheelCycle(
            cycle_id=f"C-{uuid.uuid4().hex[:8]}",
            week_id=week_id,
            net_krw=kpi.get("net_krw", 0),
            mint_krw=kpi.get("mint_krw", 0),
            burn_krw=kpi.get("burn_krw", 0),
            entropy_ratio=kpi.get("entropy_ratio", 0),
            vision_score=scores.get("vision_mastery", 0),
            risk_score=scores.get("risk_equilibrium", 0),
            innovation_score=scores.get("innovation_disruption", 0),
            learning_score=scores.get("learning_acceleration", 0),
            impact_score=scores.get("impact_amplification", 0),
            total_pillar_score=summary.get("total_score", 0),
            velocity=score.get("velocity", 0),
            momentum=momentum.get("momentum", 0),
            invest_krw=state.get("invest_krw", 0),
            grow_krw=state.get("grow_krw", 0),
            profit_krw=state.get("profit_krw", 0),
            reinvest_krw=state.get("reinvest_krw", 0),
            team=json.dumps(best_team.get("team", [])),
            team_score=best_team.get("score", 0),
        )
    
    def get_flywheel_report(self, weeks: int = 12) -> Dict[str, Any]:
        """Flywheel ì´ë ¥ ë¦¬í¬íŠ¸"""
        history = self.db.get_flywheel_history(weeks)
        
        if not history:
            return {"weeks": 0, "trend": "NO_DATA"}
        
        # íŠ¸ë Œë“œ ê³„ì‚°
        velocities = [h.velocity for h in history]
        avg_velocity = sum(velocities) / len(velocities)
        
        if len(history) >= 2:
            recent = history[0].velocity
            prev = history[1].velocity
            if recent > prev * 1.1:
                trend = "ACCELERATING"
            elif recent < prev * 0.9:
                trend = "DECELERATING"
            else:
                trend = "STEADY"
        else:
            trend = "STARTING"
        
        return {
            "weeks": len(history),
            "avg_velocity": avg_velocity,
            "current_velocity": history[0].velocity if history else 0,
            "trend": trend,
            "history": [h.to_dict() for h in history[:4]],  # ìµœê·¼ 4ì£¼
        }





















