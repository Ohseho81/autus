#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()
















#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()






#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    ğŸ§¬ AUTUS PIPELINE v1.3 FINAL - Weekly Cycle                            â•‘
â•‘                                                                                           â•‘
â•‘  v1.0: ControllerScore (PREVENTED/FIXED), Synergy Uplift                                  â•‘
â•‘  v1.1: BaseRate SOLO only, Group Synergy (k=3~4)                                          â•‘
â•‘  v1.2: BaseRate ë°±ì˜¤í”„ (SOLO â†’ ROLE_BUCKET â†’ ALL), Synergy íŒŒí‹°ì…˜                          â•‘
â•‘  v1.3: í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì‹œë„ˆì§€ í•©ì‚°, customer_id í•„ìˆ˜                                   â•‘
â•‘                                                                                           â•‘
â•‘  ì‹¤í–‰: python -m src.run_weekly_cycle                                                      â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import os
import json
import pandas as pd
from datetime import datetime, timedelta
from pathlib import Path

from .config import CFG
from .ingest import (
    read_money_events, read_burn_events, read_fx_rates,
    read_edges, read_historical_burns
)
from .normalize import (
    attach_fx_and_convert_amount_krw, explode_people_tags,
    normalize_person_ids, add_week_id, calculate_week_id
)
from .transform import (
    compute_person_aggregates, compute_weekly_totals,
    compute_burn_totals, compute_kpi, compute_indirect_stats,
    compute_person_baseline_v12, compute_project_weights_4w
)
from .synergy import (
    compute_pair_synergy_uplift_partitioned,
    compute_group_synergy_uplift_partitioned,
    aggregate_synergy_with_project_weights,
    compute_indirect_scores,
    get_top_synergy_pairs, get_negative_synergy_pairs
)
from .roles import compute_role_scores, assign_roles, get_role_summary
from .consortium import (
    find_best_team_v11, analyze_team_composition,
    suggest_team_improvements
)
from .tuning import tune_params, suggest_intervention
from .audit import AuditLogger
from .report import (
    write_json, write_markdown_report, write_csv_report,
    write_synergy_report, generate_executive_summary
)


def get_week_ids(target_date: datetime = None) -> tuple:
    """í˜„ì¬/ì „ì£¼/ì „ì „ì£¼ ID ê³„ì‚°"""
    if target_date is None:
        target_date = datetime.now()
    
    current = calculate_week_id(pd.Timestamp(target_date))
    prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=1)))
    prev_prev = calculate_week_id(pd.Timestamp(target_date - timedelta(weeks=2)))
    
    return current, prev, prev_prev


def run_weekly_cycle(
    money_path: str,
    burn_path: str,
    fx_path: str,
    edges_path: str = None,
    burn_history_path: str = None,
    out_dir: str = "data/output",
    params_path: str = None,
    audit_dir: str = None,
    target_date: datetime = None
) -> dict:
    """
    v1.3 FINAL ì£¼ê°„ ì‚¬ì´í´
    
    ì „ì²´ íŒŒì´í”„ë¼ì¸:
    1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    2. ì •ê·œí™” (Normalize)
    3. ë³€í™˜ (Transform)
    4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    9. íŒŒë¼ë¯¸í„° íŠœë‹
    10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    """
    # ê¸°ë³¸ê°’ ì„¤ì •
    if params_path is None:
        params_path = os.path.join(out_dir, "params.json")
    if audit_dir is None:
        audit_dir = out_dir
    
    os.makedirs(out_dir, exist_ok=True)
    
    # ì£¼ì°¨ ID ê³„ì‚°
    current_week, prev_week, prev_prev_week = get_week_ids(target_date)
    
    print(f"ğŸ§¬ AUTUS Pipeline v1.3 FINAL - Week {current_week}")
    print("=" * 70)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 1. ë°ì´í„° ìˆ˜ì§‘ (Ingest)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“¥ [1/10] Loading data...")
    
    money_raw = read_money_events(money_path)
    
    burn_raw = None
    if burn_path and os.path.exists(burn_path):
        burn_raw = read_burn_events(burn_path)
    else:
        burn_raw = pd.DataFrame(columns=[
            "burn_id", "date", "burn_type", "person_or_edge",
            "loss_minutes", "evidence_id", "prevented_by", "prevented_minutes"
        ])
    
    fx = None
    if fx_path and os.path.exists(fx_path):
        fx = read_fx_rates(fx_path)
    else:
        fx = pd.DataFrame(columns=["date", "currency", "fx_rate_to_krw", "source"])
    
    edges = None
    if edges_path and os.path.exists(edges_path):
        edges = read_edges(edges_path)
    
    print(f"   Money events: {len(money_raw)}")
    print(f"   Burn events: {len(burn_raw)}")
    print(f"   Customers: {money_raw['customer_id'].nunique() if 'customer_id' in money_raw.columns else 'N/A'}")
    print(f"   Projects: {money_raw['project_id'].nunique() if 'project_id' in money_raw.columns else 'N/A'}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 2. ì •ê·œí™” (Normalize)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ”„ [2/10] Normalizing...")
    
    money = attach_fx_and_convert_amount_krw(money_raw, fx)
    money_exp = explode_people_tags(money)
    money_exp = normalize_person_ids(money_exp, "person_id")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 3. ë³€í™˜ (Transform)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [3/10] Computing aggregates...")
    
    # ê°œì¸ ì§‘ê³„
    person = compute_person_aggregates(money_exp)
    
    # ì£¼ê°„ ì´ê³„
    totals = compute_weekly_totals(money)
    mint = totals["mint_krw"]
    effective_minutes = totals["effective_minutes"]
    
    # í‰ê·  Coin Rate
    avg_coin_per_min = mint / (effective_minutes + 1e-9) if effective_minutes > 0 else 0.0
    
    # Burn ì´ê³„
    burn_tot = compute_burn_totals(burn_raw, avg_coin_per_min)
    burn = burn_tot["burn_krw"]
    
    # KPI ê³„ì‚°
    prev_params = {}
    if os.path.exists(params_path):
        with open(params_path, "r", encoding="utf-8") as f:
            prev_params = json.load(f)
    
    kpi = compute_kpi(
        mint_krw=mint,
        burn_krw=burn,
        effective_minutes=effective_minutes,
        events_count=int(money["event_id"].nunique()),
        prev_coin_velocity=prev_params.get("_prev_coin_velocity")
    )
    
    # ê°„ì ‘ ê¸°ì—¬ í†µê³„
    indirect_stats = compute_indirect_stats(money)
    
    print(f"   Mint: â‚©{mint:,.0f}")
    print(f"   Burn: â‚©{burn:,.0f}")
    print(f"   Net: â‚©{kpi['net_krw']:,.0f}")
    print(f"   Entropy: {kpi['entropy_ratio']:.2%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 4. BaseRate v1.2 (SOLO â†’ ROLE_BUCKET â†’ ALL)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“Š [4/10] Computing BaseRate v1.2...")
    
    baseline = compute_person_baseline_v12(money_exp, min_events=2)
    
    solo_count = (baseline["base_rate_source"] == "SOLO").sum()
    rb_count = baseline["base_rate_source"].str.startswith("ROLE_BUCKET").sum()
    fallback_count = (baseline["base_rate_source"] == "FALLBACK_ALL").sum()
    
    print(f"   SOLO baseline: {solo_count}")
    print(f"   ROLE_BUCKET baseline: {rb_count}")
    print(f"   FALLBACK_ALL baseline: {fallback_count}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 5. Synergy v1.2 (íŒŒí‹°ì…˜ ê³„ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ¤ [5/10] Computing partitioned synergy...")
    
    pair_part = compute_pair_synergy_uplift_partitioned(money, baseline)
    group_part = compute_group_synergy_uplift_partitioned(money, baseline, k_min=3, k_max=4)
    
    print(f"   Pair synergy (partitioned): {len(pair_part)}")
    print(f"   Group synergy (partitioned): {len(group_part)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 6. Synergy v1.3 (í”„ë¡œì íŠ¸ ê°€ì¤‘ì¹˜ í•©ì‚°)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš–ï¸ [6/10] Aggregating with project weights...")
    
    project_weights = compute_project_weights_4w(money, weeks=4)
    print(f"   Projects with weights: {len(project_weights)}")
    
    pair_synergy, group_synergy = aggregate_synergy_with_project_weights(
        pair_part, group_part, project_weights
    )
    
    print(f"   Final pair synergy: {len(pair_synergy)}")
    print(f"   Final group synergy: {len(group_synergy)}")
    
    # ê°„ì ‘ ì ìˆ˜ ê³„ì‚°
    person_scored = compute_indirect_scores(person, edges, CFG.lambda_decay)
    
    # ì‹œë„ˆì§€ ë¶„ì„
    synergy_top = get_top_synergy_pairs(pair_synergy, top_n=10)
    synergy_negative = get_negative_synergy_pairs(pair_synergy)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 7. ì—­í•  ê³„ì‚° (ControllerScore v1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ‘¤ [7/10] Computing roles (ControllerScore v1)...")
    
    role_scores = compute_role_scores(money_exp, burn_raw)
    roles = assign_roles(role_scores)
    role_summary = get_role_summary(roles)
    
    print(f"   Roles assigned: {len(roles)}")
    for role, persons in role_summary.items():
        if persons:
            print(f"   - {role}: {', '.join(persons)}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 8. ì»¨ì†Œì‹œì—„ íƒìƒ‰ (Team Score v1.1)
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ† [8/10] Finding best consortium (v1.1)...")
    
    best_team = find_best_team_v11(
        person_scores=person_scored,
        pair_synergy=pair_synergy,
        group_synergy=group_synergy,
        burn_krw=burn,
        team_size=CFG.base_consortium_size,
        top_k=min(12, len(person_scored)),
        group_weight=0.6
    )
    
    team_composition = {}
    if best_team["team"]:
        team_composition = analyze_team_composition(
            best_team["team"], roles, role_scores
        )
    
    print(f"   Best team: {best_team['team']}")
    print(f"   Team score: {best_team['score']:.4f}")
    if team_composition:
        print(f"   Role coverage: {team_composition['role_coverage']:.0%}")
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 9. íŒŒë¼ë¯¸í„° íŠœë‹
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nâš™ï¸ [9/10] Tuning parameters...")
    
    tuned_params = tune_params(
        prev_params=prev_params,
        kpi={
            **kpi,
            "coin_velocity_prev": prev_params.get("_prev_coin_velocity", kpi["coin_velocity"])
        },
        indirect_stats={
            "indirect_mint_ratio": indirect_stats["indirect_mint_ratio"],
            "indirect_burn_ratio": 0.0
        },
        corr_team_to_net=None
    )
    tuned_params["_prev_coin_velocity"] = kpi["coin_velocity"]
    
    print(f"   Î±: {tuned_params['alpha']}")
    print(f"   Î»: {tuned_params['lambda']}")
    print(f"   Î³: {tuned_params['gamma']}")
    print(f"   Reason: {tuned_params['reason']}")
    
    # ê°œì… ê¶Œì¥
    role_coverage = team_composition.get("role_coverage", 0) if team_composition else 0
    synergy_avg = float(pair_synergy["synergy_uplift_per_min"].mean()) if not pair_synergy.empty else 0
    interventions = suggest_intervention(kpi, role_coverage, synergy_avg)
    
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    # 10. ê°ì‚¬ ë¡œê·¸ & ë¦¬í¬íŠ¸
    # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    print("\nğŸ“ [10/10] Writing outputs...")
    
    audit = AuditLogger(audit_dir)
    
    audit.log_kpi(current_week, kpi)
    audit.log_parameter_update(prev_params, tuned_params, kpi, tuned_params.get("reason", ""))
    audit.log_role_assignment(
        current_week,
        roles.to_dict("records") if not roles.empty else [],
        role_scores.to_dict("records") if not role_scores.empty else []
    )
    audit.log_consortium(
        current_week,
        best_team["team"],
        best_team["score"],
        team_composition
    )
    
    if interventions:
        audit.log_intervention(current_week, interventions)
    
    # íŒŒë¼ë¯¸í„° ì €ì¥
    with open(params_path, "w", encoding="utf-8") as f:
        json.dump(tuned_params, f, ensure_ascii=False, indent=2)
    
    # KPI JSON
    write_json(os.path.join(out_dir, "weekly_metrics.json"), kpi)
    
    # ì—­í•  CSV
    roles.to_csv(os.path.join(out_dir, "role_assignments.csv"), index=False, encoding="utf-8-sig")
    
    # ì»¨ì†Œì‹œì—„ JSON
    write_json(os.path.join(out_dir, "consortium_best.json"), {
        **best_team,
        "composition": team_composition,
    })
    
    # ì‹œë„ˆì§€ CSV
    if not pair_synergy.empty:
        pair_synergy.to_csv(os.path.join(out_dir, "pair_synergy.csv"), index=False, encoding="utf-8-sig")
    if not group_synergy.empty:
        group_synergy.to_csv(os.path.join(out_dir, "group_synergy.csv"), index=False, encoding="utf-8-sig")
    
    # Baseline CSV
    baseline.to_csv(os.path.join(out_dir, "baseline_rates.csv"), index=False, encoding="utf-8-sig")
    
    # ê°œì¸ ì„±ê³¼ CSV
    write_csv_report(
        os.path.join(out_dir, "person_scores.csv"),
        person_scored, role_scores
    )
    
    # ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸
    write_markdown_report(
        os.path.join(out_dir, "weekly_report.md"),
        kpi=kpi,
        best_team=best_team,
        roles=roles,
        synergy_top=synergy_top,
        synergy_negative=synergy_negative,
        params=tuned_params,
        interventions=interventions,
        week_id=current_week
    )
    
    # ê²½ì˜ì§„ ìš”ì•½
    exec_summary = generate_executive_summary(kpi, best_team)
    
    print("\n" + "=" * 70)
    print("âœ… AUTUS Pipeline v1.3 FINAL - Complete!")
    print(f"\nğŸ“‹ Executive Summary:\n{exec_summary}")
    print("\nğŸ“‚ Outputs:")
    for f in ["weekly_metrics.json", "role_assignments.csv", "consortium_best.json",
              "pair_synergy.csv", "group_synergy.csv", "baseline_rates.csv",
              "person_scores.csv", "weekly_report.md"]:
        fpath = os.path.join(out_dir, f)
        if os.path.exists(fpath):
            print(f"   - {f}")
    
    return {
        "week_id": current_week,
        "kpi": kpi,
        "best_team": best_team,
        "roles": roles.to_dict("records") if not roles.empty else [],
        "params": tuned_params,
        "interventions": interventions,
        "executive_summary": exec_summary,
    }


def main():
    """ë©”ì¸ ì—”íŠ¸ë¦¬í¬ì¸íŠ¸"""
    result = run_weekly_cycle(
        money_path="data/input/money_events.csv",
        burn_path="data/input/burn_events.csv",
        fx_path="data/input/fx_rates.csv",
        edges_path="data/input/edges.csv",
        burn_history_path="data/input/historical_burns.csv",
        out_dir="data/output",
        params_path="data/output/params.json",
        audit_dir="data/output",
    )
    
    return result


if __name__ == "__main__":
    main()





















