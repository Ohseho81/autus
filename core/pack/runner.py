"""
from __future__ import annotations

Development Pack Runner
LLM Providerë¥¼ ì„ íƒí•  ìˆ˜ ìˆëŠ” í†µí•© Pack ì‹¤í–‰ ì—”ì§„
"""
import yaml
import json
import os
from pathlib import Path
from typing import Dict, Any, Optional

# Custom exceptions for LLM provider and pack errors
class LLMProviderError(Exception):
    """Raised when there is an LLM provider configuration or usage error."""
    pass

class PackNotFoundError(Exception):
    """Raised when a requested Pack is not found."""
    pass

try:
    import sys
    ROOT = Path(__file__).resolve().parent.parent.parent
    sys.path.insert(0, str(ROOT))
    from config import PACKS_DEVELOPMENT_DIR
except ImportError:
    # fallback
    PACKS_DEVELOPMENT_DIR = Path("packs/development")


class DevPackRunner:
    """Development Pack ì‹¤í–‰ ì—”ì§„ (í†µí•© ë²„ì „)"""

    def __init__(self, provider: str = "auto", api_key: Optional[str] = None) -> None:
        """
        ì´ˆê¸°í™”

        Args:
            provider: "anthropic", "openai", "auto" (ìë™ ê°ì§€)
            api_key: API í‚¤ (ì—†ìœ¼ë©´ í™˜ê²½ë³€ìˆ˜ì—ì„œ)
        """
        self.provider = provider
        self.api_key = api_key
        self.client = None
        self.packs_dir = PACKS_DEVELOPMENT_DIR

        # Provider ì„¤ì •
        if provider == "auto":
            # í™˜ê²½ë³€ìˆ˜ì—ì„œ ìë™ ê°ì§€
            if os.getenv("ANTHROPIC_API_KEY"):
                self.provider = "anthropic"
            elif os.getenv("OPENAI_API_KEY"):
                self.provider = "anthropic"
            else:
                raise LLMProviderError("API í‚¤ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ANTHROPIC_API_KEY ë˜ëŠ” OPENAI_API_KEYë¥¼ ì„¤ì •í•˜ì„¸ìš”.")

        # LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self._init_client()

    def _init_client(self) -> None:
        """Initialize the appropriate LLM client"""
        if self.provider == "anthropic":
            try:
                from anthropic import Anthropic
                self.client = Anthropic(api_key=os.getenv("ANTHROPIC_API_KEY"))
            except ImportError:
                raise LLMProviderError("anthropic íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install anthropic")
        elif self.provider == "openai":
            try:
                from openai import OpenAI
                self.client = OpenAI(api_key=os.getenv("OPENAI_API_KEY"))
            except ImportError:
                raise LLMProviderError("openai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤: pip install openai")
        else:
            raise LLMProviderError(f"Unsupported provider: {self.provider}")
    def load_pack(self, pack_name: str) -> Dict[str, Any]:
        """
        Pack YAML ë¡œë“œ

        Args:
            pack_name: Pack ì´ë¦„ (ì˜ˆ: architect_pack)

        Returns:
            Pack ì •ì˜ ë”•ì…”ë„ˆë¦¬
        """
        pack_path = self.packs_dir / f"{pack_name}.yaml"

        if not pack_path.exists():
            raise PackNotFoundError(f"Pack not found: {pack_name} at {pack_path}")

        with open(pack_path, 'r', encoding='utf-8') as f:
            pack = yaml.safe_load(f)

        return pack

    def execute_cell(
        self,
        pack: Dict[str, Any],
        cell_name: str,
        inputs: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        Cell ì‹¤í–‰ (LLM API í˜¸ì¶œ)

        Args:
            pack: Pack ì •ì˜
            cell_name: ì‹¤í–‰í•  Cell ì´ë¦„
            inputs: Cellì— ì „ë‹¬í•  ì…ë ¥ê°’

        Returns:
            Cell ì‹¤í–‰ ê²°ê³¼
        """
        inputs = inputs or {}

        # Cell ì°¾ê¸°
        cells = pack.get("cells", [])
        cell = None
        for c in cells:
            if c.get("name") == cell_name:
                cell = c
                break

        if not cell:
            raise ValueError(f"Cell not found: {cell_name}")

        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt_template = cell.get("prompt", "")
        try:
            prompt = prompt_template.format(**inputs)
        except KeyError as e:
            raise ValueError(f"í”„ë¡¬í”„íŠ¸ í…œí”Œë¦¿ ë³€ìˆ˜ ëˆ„ë½: {e}")

        # LLM ì„¤ì •
        llm_config = pack.get("llm", {})

        print(f"ğŸ¤– Calling {self.provider.upper()} API for cell: {cell_name}")

        # Providerë³„ API í˜¸ì¶œ
        if self.provider == "anthropic":
            model = llm_config.get("model", "claude-sonnet-4-20250514")
            temperature = llm_config.get("temperature", 0.3)
            max_tokens = llm_config.get("max_tokens", 8000)

            message = self.client.messages.create(
                model=model,
                max_tokens=max_tokens,
                temperature=temperature,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ]
            )

            result = message.content[0].text

        elif self.provider == "openai":
            model = llm_config.get("model", "gpt-4")
            temperature = llm_config.get("temperature", 0.3)
            max_tokens = llm_config.get("max_tokens", 4000)

            response = self.client.chat.completions.create(
                model=model,
                messages=[
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=temperature,
                max_tokens=max_tokens
            )

            result = response.choices[0].message.content

        else:
            raise ValueError(f"ì§€ì›í•˜ì§€ ì•ŠëŠ” provider: {self.provider}")

        print(f"âœ… Cell completed: {cell_name}")

        return result

    def execute_pack(
        self,
        pack_name: str,
        inputs: Dict[str, Any] = None
    ) -> Dict[str, Any]:
        """
        Pack ì „ì²´ ì‹¤í–‰ (ëª¨ë“  Cell ìˆœì°¨ ì‹¤í–‰)

        Args:
            pack_name: Pack ì´ë¦„
            inputs: ì´ˆê¸° ì…ë ¥ê°’

        Returns:
            ì „ì²´ ì‹¤í–‰ ê²°ê³¼
        """
        inputs = inputs or {}

        print(f"ğŸš€ Executing pack: {pack_name}")

        # Pack ë¡œë“œ
        pack = self.load_pack(pack_name)

        # ê²°ê³¼ ì €ì¥
        results = {}

        # Cell ìˆœì°¨ ì‹¤í–‰
        cells = pack.get("cells", [])
        for cell in cells:
            cell_name = cell.get("name")

            # ì´ì „ Cell ì¶œë ¥ì„ ë‹¤ìŒ Cell ì…ë ¥ìœ¼ë¡œ
            cell_inputs = inputs.copy()

            # input í•„ë“œê°€ ìˆìœ¼ë©´ ì´ì „ ê²°ê³¼ ì‚¬ìš©
            if "input" in cell:
                prev_output_name = cell["input"]
                if prev_output_name in results:
                    cell_inputs[prev_output_name] = results[prev_output_name]

            # Cell ì‹¤í–‰
            result = self.execute_cell(pack, cell_name, cell_inputs)

            # ê²°ê³¼ ì €ì¥
            output_name = cell.get("output", cell_name)
            results[output_name] = result

        # ì•¡ì…˜ ì‹¤í–‰
        self.execute_actions(pack, results, inputs)

        print(f"âœ… Pack completed: {pack_name}")

        return results

    def execute_actions(
        self,
        pack: Dict[str, Any],
        results: Dict[str, Any],
        inputs: Dict[str, Any]
    ):
        """
        Pack ì•¡ì…˜ ì‹¤í–‰ (íŒŒì¼ ì“°ê¸° ë“±)

        Args:
            pack: Pack ì •ì˜
            results: Cell ì‹¤í–‰ ê²°ê³¼ë“¤
            inputs: ì´ˆê¸° ì…ë ¥ê°’
        """
        actions = pack.get("actions", [])

        for action in actions:
            action_type = action.get("type")

            if action_type == "write_file":
                # íŒŒì¼ ì“°ê¸°
                path_template = action.get("path", "")
                content_template = action.get("content", "")

                # í…œí”Œë¦¿ ë Œë”ë§
                all_vars = {**inputs, **results}
                try:
                    path = path_template.format(**all_vars)
                    content = content_template.format(**all_vars)
                except KeyError as e:
                    print(f"âš ï¸  ì•¡ì…˜ ë³€ìˆ˜ ëˆ„ë½: {e}, ìŠ¤í‚µ")
                    continue

                # ë””ë ‰í† ë¦¬ ìƒì„±
                if action.get("create_dirs", False):
                    Path(path).parent.mkdir(parents=True, exist_ok=True)

                # íŒŒì¼ ì“°ê¸°
                with open(path, 'w', encoding='utf-8') as f:
                    f.write(content)

                print(f"ğŸ“ File written: {path}")

            elif action_type == "log":
                # ë¡œê·¸ ì¶œë ¥
                message_template = action.get("message", "")
                all_vars = {**inputs, **results}
                try:
                    message = message_template.format(**all_vars)
                    level = action.get("level", "info")
                    print(f"ğŸ“‹ [{level.upper()}] {message}")
                except KeyError as e:
                    print(f"âš ï¸  ë¡œê·¸ ë³€ìˆ˜ ëˆ„ë½: {e}")


# CLI ì¸í„°í˜ì´ìŠ¤
if __name__ == "__main__":
    import sys

    if len(sys.argv) < 2:
        print("Usage: python runner.py <pack_name> [inputs_json] [--provider anthropic|openai]")
        sys.exit(1)

    pack_name = sys.argv[1]
    inputs = {}
    provider = "auto"

    # ì¸ì íŒŒì‹±
    for i, arg in enumerate(sys.argv[2:], 2):
        if arg == "--provider" and i + 1 < len(sys.argv):
            provider = sys.argv[i + 1]
        elif arg.startswith("{"):
            inputs = json.loads(arg)

    # ì‹¤í–‰
    try:
        runner = DevPackRunner(provider=provider)
        results = runner.execute_pack(pack_name, inputs)

        print("\n" + "="*50)
        print("Results:")
        print(json.dumps(results, indent=2, ensure_ascii=False))
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)
