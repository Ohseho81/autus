// ================================================================
// VOICE LISTENER ENGINE (ìŒì„± ì¸ì‹ ì—”ì§„)
// Web Speech API + Whisper.js ì§€ì›
// ================================================================

// ================================================================
// WEB SPEECH API (ë¸Œë¼ìš°ì € ë‚´ì¥)
// ================================================================

const WebSpeechRecognizer = {
    recognition: null,
    isSupported: false,
    isListening: false,
    
    /**
     * ì´ˆê¸°í™”
     */
    init(lang = 'ko-KR') {
        const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
        
        if (!SpeechRecognition) {
            console.warn('[WebSpeech] ì´ ë¸Œë¼ìš°ì €ì—ì„œ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
            this.isSupported = false;
            return false;
        }
        
        this.recognition = new SpeechRecognition();
        this.recognition.lang = lang;
        this.recognition.continuous = true;
        this.recognition.interimResults = true;
        this.recognition.maxAlternatives = 3;
        
        this.isSupported = true;
        console.log(`[WebSpeech] ì´ˆê¸°í™” ì™„ë£Œ (ì–¸ì–´: ${lang})`);
        
        return true;
    },
    
    /**
     * ìŒì„± ì¸ì‹ ì‹œì‘
     */
    start(callbacks = {}) {
        if (!this.isSupported) {
            throw new Error('Web Speech APIê°€ ì§€ì›ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤');
        }
        
        return new Promise((resolve, reject) => {
            const results = [];
            let finalTranscript = '';
            
            this.recognition.onresult = (event) => {
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    const confidence = event.results[i][0].confidence;
                    
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                        results.push({
                            text: transcript,
                            confidence,
                            isFinal: true,
                            timestamp: Date.now()
                        });
                        
                        if (callbacks.onResult) {
                            callbacks.onResult({ text: transcript, confidence, isFinal: true });
                        }
                    } else {
                        interimTranscript += transcript;
                        
                        if (callbacks.onInterim) {
                            callbacks.onInterim({ text: transcript, confidence, isFinal: false });
                        }
                    }
                }
            };
            
            this.recognition.onerror = (event) => {
                console.error('[WebSpeech] ì˜¤ë¥˜:', event.error);
                if (callbacks.onError) callbacks.onError(event.error);
                reject(new Error(event.error));
            };
            
            this.recognition.onend = () => {
                this.isListening = false;
                
                if (callbacks.onEnd) callbacks.onEnd();
                
                resolve({
                    transcript: finalTranscript.trim(),
                    results,
                    confidence: results.length > 0 
                        ? results.reduce((a, b) => a + b.confidence, 0) / results.length 
                        : 0
                });
            };
            
            this.recognition.start();
            this.isListening = true;
            
            if (callbacks.onStart) callbacks.onStart();
            console.log('[WebSpeech] ìŒì„± ì¸ì‹ ì‹œì‘');
        });
    },
    
    /**
     * ìŒì„± ì¸ì‹ ì¤‘ì§€
     */
    stop() {
        if (this.recognition && this.isListening) {
            this.recognition.stop();
            this.isListening = false;
            console.log('[WebSpeech] ìŒì„± ì¸ì‹ ì¤‘ì§€');
        }
    },
    
    /**
     * ì–¸ì–´ ë³€ê²½
     */
    setLanguage(lang) {
        if (this.recognition) {
            this.recognition.lang = lang;
            console.log(`[WebSpeech] ì–¸ì–´ ë³€ê²½: ${lang}`);
        }
    }
};

// ================================================================
// AUDIO RECORDER (ì˜¤ë””ì˜¤ ë…¹ìŒ)
// ================================================================

const AudioRecorder = {
    mediaRecorder: null,
    audioChunks: [],
    stream: null,
    
    /**
     * ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œ ìš”ì²­
     */
    async requestPermission() {
        try {
            this.stream = await navigator.mediaDevices.getUserMedia({ 
                audio: {
                    echoCancellation: true,
                    noiseSuppression: true,
                    sampleRate: 16000
                } 
            });
            console.log('[AudioRecorder] ë§ˆì´í¬ ê¶Œí•œ íšë“');
            return true;
        } catch (err) {
            console.error('[AudioRecorder] ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨:', err);
            throw new Error('ë§ˆì´í¬ ì ‘ê·¼ ê¶Œí•œì´ í•„ìš”í•©ë‹ˆë‹¤');
        }
    },
    
    /**
     * ë…¹ìŒ ì‹œì‘
     */
    async start() {
        if (!this.stream) {
            await this.requestPermission();
        }
        
        this.audioChunks = [];
        this.mediaRecorder = new MediaRecorder(this.stream, {
            mimeType: 'audio/webm;codecs=opus'
        });
        
        this.mediaRecorder.ondataavailable = (event) => {
            if (event.data.size > 0) {
                this.audioChunks.push(event.data);
            }
        };
        
        this.mediaRecorder.start(100); // 100ms ê°„ê²©ìœ¼ë¡œ ë°ì´í„° ìˆ˜ì§‘
        console.log('[AudioRecorder] ë…¹ìŒ ì‹œì‘');
    },
    
    /**
     * ë…¹ìŒ ì¤‘ì§€ ë° Blob ë°˜í™˜
     */
    stop() {
        return new Promise((resolve) => {
            if (!this.mediaRecorder) {
                resolve(null);
                return;
            }
            
            this.mediaRecorder.onstop = () => {
                const blob = new Blob(this.audioChunks, { type: 'audio/webm' });
                console.log(`[AudioRecorder] ë…¹ìŒ ì™„ë£Œ: ${(blob.size / 1024).toFixed(1)} KB`);
                resolve(blob);
            };
            
            this.mediaRecorder.stop();
        });
    },
    
    /**
     * ë¦¬ì†ŒìŠ¤ í•´ì œ
     */
    release() {
        if (this.stream) {
            this.stream.getTracks().forEach(track => track.stop());
            this.stream = null;
        }
        this.mediaRecorder = null;
        this.audioChunks = [];
    }
};

// ================================================================
// AUDIO ANALYZER (ì˜¤ë””ì˜¤ ë¶„ì„)
// ================================================================

const AudioAnalyzer = {
    audioContext: null,
    analyser: null,
    
    /**
     * ì˜¤ë””ì˜¤ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
     */
    init() {
        this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
        this.analyser = this.audioContext.createAnalyser();
        this.analyser.fftSize = 2048;
    },
    
    /**
     * ì‹¤ì‹œê°„ ë³¼ë¥¨ ë ˆë²¨ ê°€ì ¸ì˜¤ê¸°
     */
    getVolumeLevel(stream) {
        if (!this.audioContext) this.init();
        
        const source = this.audioContext.createMediaStreamSource(stream);
        source.connect(this.analyser);
        
        const dataArray = new Uint8Array(this.analyser.frequencyBinCount);
        this.analyser.getByteFrequencyData(dataArray);
        
        const average = dataArray.reduce((a, b) => a + b, 0) / dataArray.length;
        return average / 255; // 0-1 ë²”ìœ„
    },
    
    /**
     * ìŒì„± ê°ì • ì¶”ì • (ë³¼ë¥¨/ì†ë„ ê¸°ë°˜ ê°„ë‹¨ ë¶„ì„)
     */
    estimateEmotion(audioFeatures) {
        const { volume, speed, pitch } = audioFeatures;
        
        // ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹± ê¸°ë°˜ ê°ì • ì¶”ì •
        if (volume > 0.7 && speed > 1.2) {
            return { emotion: 'excited', confidence: 0.6 };
        }
        if (volume < 0.3 && speed < 0.8) {
            return { emotion: 'calm', confidence: 0.6 };
        }
        if (volume > 0.5 && pitch > 1.1) {
            return { emotion: 'happy', confidence: 0.5 };
        }
        
        return { emotion: 'neutral', confidence: 0.7 };
    },
    
    /**
     * ë§í•˜ê¸° ì†ë„ ê³„ì‚° (WPM)
     */
    calculateSpeakingRate(text, durationSeconds) {
        const wordCount = text.split(/\s+/).filter(w => w).length;
        const wpm = (wordCount / durationSeconds) * 60;
        
        return {
            wordCount,
            durationSeconds,
            wordsPerMinute: Math.round(wpm),
            pace: wpm > 150 ? 'fast' : wpm > 100 ? 'normal' : 'slow'
        };
    }
};

// ================================================================
// TEXT PROCESSOR (í…ìŠ¤íŠ¸ ì²˜ë¦¬)
// ================================================================

const VoiceTextProcessor = {
    /**
     * í…ìŠ¤íŠ¸ ì •ê·œí™”
     */
    normalize(text) {
        return text
            .trim()
            .replace(/\s+/g, ' ')
            .replace(/\.{2,}/g, '.')
            .replace(/\?{2,}/g, '?');
    },
    
    /**
     * ë¬¸ì¥ ë¶„ë¦¬
     */
    splitSentences(text) {
        return text
            .split(/[.!?]+/)
            .map(s => s.trim())
            .filter(s => s.length > 0);
    },
    
    /**
     * í‚¤ì›Œë“œ ì¶”ì¶œ
     */
    extractKeywords(text) {
        const words = text.match(/[ê°€-í£]{2,}|[a-zA-Z]{3,}/g) || [];
        const freq = {};
        
        words.forEach(word => {
            const normalized = word.toLowerCase();
            freq[normalized] = (freq[normalized] || 0) + 1;
        });
        
        return Object.entries(freq)
            .sort((a, b) => b[1] - a[1])
            .slice(0, 10)
            .map(([word, count]) => ({ word, count }));
    },
    
    /**
     * ì˜ë„ ê°ì§€ (ê°„ë‹¨í•œ íŒ¨í„´ ë§¤ì¹­)
     */
    detectIntent(text) {
        const lowerText = text.toLowerCase();
        
        const patterns = {
            question: /[?ï¼Ÿ]|ë­|ì–´ë””|ì–¸ì œ|ëˆ„ê°€|ì™œ|ì–´ë–»ê²Œ|what|where|when|who|why|how/,
            command: /í•´ì¤˜|í•´ë¼|í•˜ì„¸ìš”|í•´ì£¼ì„¸ìš”|please|do|make|create/,
            greeting: /ì•ˆë…•|ë°˜ê°€|hello|hi|hey/,
            farewell: /ì˜ê°€|bye|goodbye|ì•ˆë…•íˆ/,
            affirmative: /ë„¤|ì˜ˆ|ì‘|ë§ì•„|ê·¸ë˜|yes|yeah|right|correct/,
            negative: /ì•„ë‹ˆ|ì•„ë‡¨|no|nope|wrong/
        };
        
        for (const [intent, pattern] of Object.entries(patterns)) {
            if (pattern.test(lowerText)) {
                return { intent, confidence: 0.7 };
            }
        }
        
        return { intent: 'statement', confidence: 0.5 };
    }
};

// ================================================================
// PHYSICS CONVERTER (ë¬¼ë¦¬ ì†ì„± ë³€í™˜)
// ================================================================

const VoicePhysicsConverter = {
    /**
     * ìŒì„± ì¸ì‹ ê²°ê³¼ë¥¼ ë¬¼ë¦¬ ì†ì„±ìœ¼ë¡œ ë³€í™˜
     */
    convert(voiceResult, audioFeatures = {}) {
        const { transcript, confidence, results } = voiceResult;
        const text = transcript || '';
        
        // 1. MASS = í…ìŠ¤íŠ¸ ì–‘ + ë‹¨ì–´ ìˆ˜
        const wordCount = text.split(/\s+/).filter(w => w).length;
        const mass = Math.log10(text.length + 1) * 5 + wordCount * 0.5;
        
        // 2. ENERGY = ì‹ ë¢°ë„ + ë³¼ë¥¨
        const volumeBonus = (audioFeatures.volume || 0.5) * 20;
        const energy = (confidence || 0.5) * 80 + volumeBonus;
        
        // 3. ENTROPY = ë‹¨ì–´ ë‹¤ì–‘ì„±
        const keywords = VoiceTextProcessor.extractKeywords(text);
        const uniqueRatio = keywords.length / Math.max(wordCount, 1);
        const entropy = Math.min(uniqueRatio * 2, 1);
        
        // 4. VELOCITY = ë§í•˜ê¸° ì†ë„
        const duration = audioFeatures.duration || 10;
        const wpm = (wordCount / duration) * 60;
        const velocity = Math.min(wpm / 100, 2);
        
        // 5. ì¶”ê°€ ë¶„ì„
        const sentences = VoiceTextProcessor.splitSentences(text);
        const intent = VoiceTextProcessor.detectIntent(text);
        const emotion = AudioAnalyzer.estimateEmotion(audioFeatures);
        
        return {
            mass: Math.round(mass * 100) / 100,
            energy: Math.round(energy * 100) / 100,
            entropy: Math.round(entropy * 1000) / 1000,
            velocity: Math.round(velocity * 100) / 100,
            
            metadata: {
                textLength: text.length,
                wordCount,
                sentenceCount: sentences.length,
                confidence,
                speakingRate: {
                    wpm: Math.round(wpm),
                    pace: wpm > 150 ? 'fast' : wpm > 100 ? 'normal' : 'slow'
                },
                emotion,
                intent,
                keywords: keywords.slice(0, 5)
            },
            
            rawTranscript: text,
            analyzedAt: new Date().toISOString()
        };
    }
};

// ================================================================
// VOICE LISTENER ENGINE (í†µí•© ì—”ì§„)
// ================================================================

export const VoiceListener = {
    // ì»´í¬ë„ŒíŠ¸
    webSpeech: WebSpeechRecognizer,
    recorder: AudioRecorder,
    analyzer: AudioAnalyzer,
    processor: VoiceTextProcessor,
    converter: VoicePhysicsConverter,
    
    // ìƒíƒœ
    isInitialized: false,
    isListening: false,
    history: [],
    lastResult: null,
    
    // ì½œë°±
    onTranscript: null,
    onInterim: null,
    
    /**
     * ì´ˆê¸°í™”
     */
    async init(lang = 'ko-KR') {
        console.log('[VoiceListener] ì´ˆê¸°í™” ì¤‘...');
        
        // Web Speech API ì´ˆê¸°í™”
        this.webSpeech.init(lang);
        
        // Audio Analyzer ì´ˆê¸°í™”
        this.analyzer.init();
        
        this.isInitialized = true;
        console.log('[VoiceListener] ì´ˆê¸°í™” ì™„ë£Œ');
        
        return this;
    },
    
    /**
     * ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹ ì‹œì‘
     */
    async startListening(options = {}) {
        if (!this.isInitialized) {
            await this.init(options.lang);
        }
        
        if (this.isListening) {
            console.warn('[VoiceListener] ì´ë¯¸ ë“£ëŠ” ì¤‘ì…ë‹ˆë‹¤');
            return;
        }
        
        this.isListening = true;
        const startTime = Date.now();
        
        console.log('[VoiceListener] ìŒì„± ì¸ì‹ ì‹œì‘...');
        
        try {
            const result = await this.webSpeech.start({
                onResult: (data) => {
                    if (this.onTranscript) this.onTranscript(data);
                },
                onInterim: (data) => {
                    if (this.onInterim) this.onInterim(data);
                },
                onStart: options.onStart,
                onEnd: options.onEnd,
                onError: options.onError
            });
            
            const duration = (Date.now() - startTime) / 1000;
            
            // ë¬¼ë¦¬ ì†ì„± ë³€í™˜
            const physics = this.converter.convert(result, { duration });
            
            // ê²°ê³¼ ì €ì¥
            this.lastResult = { voice: result, physics };
            this.history.push({
                timestamp: new Date().toISOString(),
                duration,
                textLength: result.transcript.length,
                confidence: result.confidence
            });
            
            return { voice: result, physics };
            
        } finally {
            this.isListening = false;
        }
    },
    
    /**
     * ìŒì„± ì¸ì‹ ì¤‘ì§€
     */
    stopListening() {
        this.webSpeech.stop();
        this.isListening = false;
        console.log('[VoiceListener] ìŒì„± ì¸ì‹ ì¤‘ì§€');
    },
    
    /**
     * ë…¹ìŒ í›„ ì²˜ë¦¬ (íŒŒì¼ìš©)
     */
    async recordAndProcess(durationMs = 10000) {
        console.log(`[VoiceListener] ${durationMs/1000}ì´ˆ ë…¹ìŒ ì‹œì‘...`);
        
        await this.recorder.start();
        
        // ì§€ì •ëœ ì‹œê°„ ë™ì•ˆ ë…¹ìŒ
        await new Promise(resolve => setTimeout(resolve, durationMs));
        
        const audioBlob = await this.recorder.stop();
        
        // Web Speech APIë¡œ ë™ì‹œì— ì¸ì‹í–ˆë‹¤ë©´ ê·¸ ê²°ê³¼ ì‚¬ìš©
        // ì•„ë‹ˆë©´ ë…¹ìŒëœ ì˜¤ë””ì˜¤ ë°˜í™˜
        
        return {
            audioBlob,
            duration: durationMs / 1000,
            size: audioBlob ? audioBlob.size : 0
        };
    },
    
    /**
     * ìš”ì•½ ìƒì„±
     */
    generateSummary(result) {
        const { voice, physics } = result;
        
        return {
            transcript: voice.transcript.substring(0, 200) + 
                       (voice.transcript.length > 200 ? '...' : ''),
            
            interpretation: {
                mass: physics.mass > 20 
                    ? 'ğŸ“Š í’ë¶€í•œ ë°œí™”ëŸ‰' 
                    : physics.mass > 10 
                        ? 'ğŸ“‹ ì ì • ë°œí™”ëŸ‰'
                        : 'ğŸ“ ì§§ì€ ë°œí™”',
                
                energy: physics.energy > 70 
                    ? 'âœ¨ ë†’ì€ ì¸ì‹ ì‹ ë¢°ë„'
                    : physics.energy > 50 
                        ? 'ğŸ‘ ì–‘í˜¸í•œ ì¸ì‹ í’ˆì§ˆ'
                        : 'âš ï¸ ì¸ì‹ í’ˆì§ˆ ì£¼ì˜',
                
                velocity: physics.metadata.speakingRate.pace === 'fast'
                    ? 'ğŸš€ ë¹ ë¥¸ ë§í•˜ê¸° ì†ë„'
                    : physics.metadata.speakingRate.pace === 'normal'
                        ? 'â¡ï¸ ë³´í†µ ì†ë„'
                        : 'ğŸ¢ ëŠë¦° ì†ë„'
            },
            
            insights: {
                intent: physics.metadata.intent.intent,
                emotion: physics.metadata.emotion.emotion,
                topKeywords: physics.metadata.keywords.map(k => k.word)
            }
        };
    },
    
    /**
     * ìƒíƒœ ì¡°íšŒ
     */
    getStatus() {
        return {
            initialized: this.isInitialized,
            listening: this.isListening,
            webSpeechSupported: this.webSpeech.isSupported,
            historyCount: this.history.length,
            lastResult: this.lastResult ? {
                textLength: this.lastResult.voice.transcript.length,
                confidence: this.lastResult.voice.confidence
            } : null
        };
    },
    
    /**
     * ë¦¬ì†ŒìŠ¤ í•´ì œ
     */
    release() {
        this.webSpeech.stop();
        this.recorder.release();
        this.isListening = false;
        console.log('[VoiceListener] ë¦¬ì†ŒìŠ¤ í•´ì œ');
    }
};

// ================================================================
// í…ŒìŠ¤íŠ¸ í•¨ìˆ˜
// ================================================================

export async function testVoiceListener() {
    console.log('='.repeat(50));
    console.log('[TEST] VoiceListener í…ŒìŠ¤íŠ¸');
    console.log('='.repeat(50));
    
    // í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸
    const sampleText = 'ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ìˆ˜ì—…ì€ ìˆ˜í•™ì…ë‹ˆë‹¤. ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?';
    
    console.log('\n[TEST] í…ìŠ¤íŠ¸ ì²˜ë¦¬ í…ŒìŠ¤íŠ¸:');
    console.log('ì…ë ¥:', sampleText);
    
    const normalized = VoiceTextProcessor.normalize(sampleText);
    console.log('ì •ê·œí™”:', normalized);
    
    const sentences = VoiceTextProcessor.splitSentences(sampleText);
    console.log('ë¬¸ì¥ ë¶„ë¦¬:', sentences);
    
    const keywords = VoiceTextProcessor.extractKeywords(sampleText);
    console.log('í‚¤ì›Œë“œ:', keywords);
    
    const intent = VoiceTextProcessor.detectIntent(sampleText);
    console.log('ì˜ë„:', intent);
    
    // ë¬¼ë¦¬ ë³€í™˜ í…ŒìŠ¤íŠ¸
    console.log('\n[TEST] ë¬¼ë¦¬ ì†ì„± ë³€í™˜:');
    const physics = VoicePhysicsConverter.convert({
        transcript: sampleText,
        confidence: 0.85,
        results: []
    }, { duration: 5, volume: 0.6 });
    
    console.log('Mass:', physics.mass);
    console.log('Energy:', physics.energy);
    console.log('Entropy:', physics.entropy);
    console.log('Velocity:', physics.velocity);
    
    console.log('\n' + '='.repeat(50));
    console.log('[TEST] ì™„ë£Œ!');
    console.log('ì‹¤ì œ ìŒì„± ì¸ì‹ í…ŒìŠ¤íŠ¸: VoiceListener.startListening()');
    console.log('='.repeat(50));
}

// ================================================================
// EXPORTS
// ================================================================

export { 
    WebSpeechRecognizer, 
    AudioRecorder, 
    AudioAnalyzer, 
    VoiceTextProcessor, 
    VoicePhysicsConverter 
};

export default VoiceListener;




