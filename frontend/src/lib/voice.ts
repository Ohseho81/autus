/**
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * ğŸ¤ Voice Input â€” ìŒì„± ì¸ì‹
 * â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
 * 
 * Web Speech APIë¥¼ í™œìš©í•œ ìŒì„± ì…ë ¥:
 * - ì‹¤ì‹œê°„ ìŒì„± ì¸ì‹
 * - ëª…ë ¹ì–´ ê°ì§€
 * - ê²°ì • ì…ë ¥
 * - í–…í‹± í”¼ë“œë°±
 */

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Web Speech API Type Declarations
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

interface SpeechRecognitionErrorEvent extends Event {
  error: string;
  message?: string;
}

interface SpeechRecognitionResult {
  readonly isFinal: boolean;
  readonly length: number;
  item(index: number): SpeechRecognitionAlternative;
  [index: number]: SpeechRecognitionAlternative;
}

interface SpeechRecognitionAlternative {
  readonly transcript: string;
  readonly confidence: number;
}

interface SpeechRecognitionResultList {
  readonly length: number;
  item(index: number): SpeechRecognitionResult;
  [index: number]: SpeechRecognitionResult;
}

interface SpeechRecognitionEvent extends Event {
  readonly resultIndex: number;
  readonly results: SpeechRecognitionResultList;
}

interface SpeechRecognition extends EventTarget {
  continuous: boolean;
  interimResults: boolean;
  lang: string;
  maxAlternatives: number;
  onstart: ((this: SpeechRecognition, ev: Event) => void) | null;
  onend: ((this: SpeechRecognition, ev: Event) => void) | null;
  onerror: ((this: SpeechRecognition, ev: SpeechRecognitionErrorEvent) => void) | null;
  onresult: ((this: SpeechRecognition, ev: SpeechRecognitionEvent) => void) | null;
  start(): void;
  stop(): void;
  abort(): void;
}

// eslint-disable-next-line no-var
declare var SpeechRecognition: {
  prototype: SpeechRecognition;
  new(): SpeechRecognition;
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Types
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export interface VoiceConfig {
  language?: string;
  continuous?: boolean;
  interimResults?: boolean;
  maxAlternatives?: number;
}

export interface VoiceResult {
  text: string;
  confidence: number;
  isFinal: boolean;
  command?: VoiceCommand;
}

export type VoiceCommand = 
  | { type: 'accept' }
  | { type: 'reject' }
  | { type: 'skip' }
  | { type: 'undo' }
  | { type: 'status' }
  | { type: 'help' }
  | { type: 'decision'; text: string };

export type VoiceState = 'idle' | 'listening' | 'processing' | 'error';

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Constants
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

const COMMANDS: Record<string, VoiceCommand['type']> = {
  // Accept
  'ì˜ˆ': 'accept',
  'ë„¤': 'accept',
  'ìˆ˜ë½': 'accept',
  'í™•ì¸': 'accept',
  'yes': 'accept',
  'accept': 'accept',
  'ìŠ¹ì¸': 'accept',
  
  // Reject
  'ì•„ë‹ˆì˜¤': 'reject',
  'ì•„ë‹ˆ': 'reject',
  'ê±°ì ˆ': 'reject',
  'ì·¨ì†Œ': 'reject',
  'no': 'reject',
  'reject': 'reject',
  
  // Skip
  'ê±´ë„ˆë›°ê¸°': 'skip',
  'ìŠ¤í‚µ': 'skip',
  'ë‹¤ìŒ': 'skip',
  'skip': 'skip',
  'next': 'skip',
  
  // Undo
  'ë˜ëŒë¦¬ê¸°': 'undo',
  'ì·¨ì†Œí•˜ê¸°': 'undo',
  'undo': 'undo',
  
  // Status
  'ìƒíƒœ': 'status',
  'í˜„ì¬': 'status',
  'status': 'status',
  
  // Help
  'ë„ì›€ë§': 'help',
  'ëª…ë ¹ì–´': 'help',
  'help': 'help',
};

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Voice Recognition
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class VoiceRecognition {
  private recognition: SpeechRecognition | null = null;
  private config: Required<VoiceConfig>;
  private state: VoiceState = 'idle';
  private onResult?: (result: VoiceResult) => void;
  private onStateChange?: (state: VoiceState) => void;
  private onError?: (error: string) => void;

  constructor(config: VoiceConfig = {}) {
    this.config = {
      language: config.language || 'ko-KR',
      continuous: config.continuous ?? true,
      interimResults: config.interimResults ?? true,
      maxAlternatives: config.maxAlternatives || 1,
    };

    this.initRecognition();
  }

  /**
   * ìŒì„± ì¸ì‹ ì´ˆê¸°í™”
   */
  private initRecognition(): void {
    const SpeechRecognition = 
      (window as any).SpeechRecognition || 
      (window as any).webkitSpeechRecognition;

    if (!SpeechRecognition) {
      console.warn('Speech Recognition not supported');
      return;
    }

    this.recognition = new SpeechRecognition();
    this.recognition.lang = this.config.language;
    this.recognition.continuous = this.config.continuous;
    this.recognition.interimResults = this.config.interimResults;
    this.recognition.maxAlternatives = this.config.maxAlternatives;

    this.recognition.onstart = () => {
      this.setState('listening');
    };

    this.recognition.onresult = (event: SpeechRecognitionEvent) => {
      const result = event.results[event.resultIndex];
      const transcript = result[0].transcript.trim();
      const confidence = result[0].confidence;
      const isFinal = result.isFinal;

      const voiceResult: VoiceResult = {
        text: transcript,
        confidence,
        isFinal,
        command: this.parseCommand(transcript),
      };

      this.onResult?.(voiceResult);

      // í–…í‹± í”¼ë“œë°±
      if (isFinal && voiceResult.command) {
        this.hapticFeedback();
      }
    };

    this.recognition.onerror = (event: SpeechRecognitionErrorEvent) => {
      this.setState('error');
      this.onError?.(event.error);
    };

    this.recognition.onend = () => {
      if (this.state === 'listening' && this.config.continuous) {
        // ìë™ ì¬ì‹œì‘
        this.recognition?.start();
      } else {
        this.setState('idle');
      }
    };
  }

  /**
   * ëª…ë ¹ì–´ íŒŒì‹±
   */
  private parseCommand(text: string): VoiceCommand | undefined {
    const lower = text.toLowerCase();

    // ì •í™•í•œ ë§¤ì¹­
    for (const [keyword, type] of Object.entries(COMMANDS)) {
      if (lower === keyword.toLowerCase()) {
        if (type === 'decision') {
          return { type: 'decision', text };
        }
        return { type } as VoiceCommand;
      }
    }

    // ë¶€ë¶„ ë§¤ì¹­
    for (const [keyword, type] of Object.entries(COMMANDS)) {
      if (lower.includes(keyword.toLowerCase())) {
        if (type === 'decision') {
          return { type: 'decision', text };
        }
        return { type } as VoiceCommand;
      }
    }

    // ê²°ì • í…ìŠ¤íŠ¸ë¡œ ì²˜ë¦¬
    if (text.length >= 5) {
      return { type: 'decision', text };
    }

    return undefined;
  }

  /**
   * ìƒíƒœ ë³€ê²½
   */
  private setState(state: VoiceState): void {
    this.state = state;
    this.onStateChange?.(state);
  }

  /**
   * í–…í‹± í”¼ë“œë°±
   */
  private hapticFeedback(): void {
    if ('vibrate' in navigator) {
      navigator.vibrate(50);
    }
  }

  /**
   * ì¸ì‹ ì‹œì‘
   */
  start(): boolean {
    if (!this.recognition) {
      this.onError?.('Speech Recognition not available');
      return false;
    }

    try {
      this.recognition.start();
      return true;
    } catch (error) {
      console.error('Voice recognition start error:', error);
      return false;
    }
  }

  /**
   * ì¸ì‹ ì¤‘ì§€
   */
  stop(): void {
    if (this.recognition) {
      this.setState('idle');
      this.recognition.stop();
    }
  }

  /**
   * ì¼ì‹œ ì¤‘ì§€
   */
  pause(): void {
    if (this.recognition) {
      this.recognition.abort();
    }
  }

  /**
   * ì½œë°± ì„¤ì •
   */
  setCallbacks(
    onResult: (result: VoiceResult) => void,
    onStateChange?: (state: VoiceState) => void,
    onError?: (error: string) => void
  ): void {
    this.onResult = onResult;
    this.onStateChange = onStateChange;
    this.onError = onError;
  }

  /**
   * í˜„ì¬ ìƒíƒœ
   */
  getState(): VoiceState {
    return this.state;
  }

  /**
   * ì§€ì› ì—¬ë¶€
   */
  static isSupported(): boolean {
    return !!(
      (window as any).SpeechRecognition ||
      (window as any).webkitSpeechRecognition
    );
  }

  /**
   * ì–¸ì–´ ë³€ê²½
   */
  setLanguage(language: string): void {
    this.config.language = language;
    if (this.recognition) {
      this.recognition.lang = language;
    }
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Voice Synthesis (TTS)
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export class VoiceSynthesis {
  private synth: SpeechSynthesis;
  private voice: SpeechSynthesisVoice | null = null;
  private rate: number = 1;
  private pitch: number = 1;
  private volume: number = 1;

  constructor() {
    this.synth = window.speechSynthesis;
    this.loadVoice();
  }

  /**
   * í•œêµ­ì–´ ìŒì„± ë¡œë“œ
   */
  private loadVoice(): void {
    const loadVoices = () => {
      const voices = this.synth.getVoices();
      this.voice = voices.find(v => v.lang.startsWith('ko')) || voices[0];
    };

    if (this.synth.onvoiceschanged !== undefined) {
      this.synth.onvoiceschanged = loadVoices;
    }
    loadVoices();
  }

  /**
   * í…ìŠ¤íŠ¸ ì½ê¸°
   */
  speak(text: string): void {
    if (this.synth.speaking) {
      this.synth.cancel();
    }

    const utterance = new SpeechSynthesisUtterance(text);
    utterance.voice = this.voice;
    utterance.rate = this.rate;
    utterance.pitch = this.pitch;
    utterance.volume = this.volume;

    this.synth.speak(utterance);
  }

  /**
   * ì¤‘ì§€
   */
  stop(): void {
    this.synth.cancel();
  }

  /**
   * ì„¤ì •
   */
  setOptions(options: { rate?: number; pitch?: number; volume?: number }): void {
    if (options.rate !== undefined) this.rate = options.rate;
    if (options.pitch !== undefined) this.pitch = options.pitch;
    if (options.volume !== undefined) this.volume = options.volume;
  }

  /**
   * ì§€ì› ì—¬ë¶€
   */
  static isSupported(): boolean {
    return 'speechSynthesis' in window;
  }
}

// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
// Factory
// â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

export function createVoiceRecognition(config?: VoiceConfig): VoiceRecognition {
  return new VoiceRecognition(config);
}

export function createVoiceSynthesis(): VoiceSynthesis {
  return new VoiceSynthesis();
}

export default { VoiceRecognition, VoiceSynthesis };
