"""
AUTUS AI Analyzer v14.0
========================
ìˆ˜ì§‘ëœ ë°ì´í„° AI ë¶„ì„

ê¸°ëŠ¥:
- ì´ë©”ì¼ ìš”ì•½ ë° ìš°ì„ ìˆœìœ„
- ì¼ì • ìµœì í™” ì œì•ˆ
- ë©”ì‹œì§€ ê°ì„± ë¶„ì„
- ë¬¸ì„œ ìžë™ ë¶„ë¥˜
- ì¸ì‚¬ì´íŠ¸ ìƒì„±
"""

import os
import logging
from datetime import datetime, timedelta
from typing import Optional, Dict, Any, List
from dataclasses import dataclass
from enum import Enum

from integrations.data_hub import DataHub, DataType, UnifiedData, get_data_hub

logger = logging.getLogger(__name__)

# ============================================
# Analysis Types
# ============================================

class AnalysisType(str, Enum):
    SUMMARY = "summary"           # ìš”ì•½
    PRIORITY = "priority"         # ìš°ì„ ìˆœìœ„
    SENTIMENT = "sentiment"       # ê°ì„±
    CATEGORY = "category"         # ë¶„ë¥˜
    INSIGHT = "insight"           # ì¸ì‚¬ì´íŠ¸
    RECOMMENDATION = "recommendation"  # ì¶”ì²œ
    ANOMALY = "anomaly"           # ì´ìƒ ê°ì§€

@dataclass
class AnalysisResult:
    """ë¶„ì„ ê²°ê³¼"""
    type: AnalysisType
    data_type: DataType
    result: Dict[str, Any]
    confidence: float = 0.0
    timestamp: datetime = None
    
    def __post_init__(self):
        if self.timestamp is None:
            self.timestamp = datetime.utcnow()

# ============================================
# AI Analyzer
# ============================================

class AIAnalyzer:
    """
    AI ê¸°ë°˜ ë°ì´í„° ë¶„ì„ê¸°
    
    ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ì¸ì‚¬ì´íŠ¸ ì œê³µ
    """
    
    def __init__(self):
        self.data_hub = get_data_hub()
        self.llm_api_key = os.getenv("OPENAI_API_KEY") or os.getenv("ANTHROPIC_API_KEY")
    
    async def analyze_emails(self, user_id: str) -> List[AnalysisResult]:
        """ì´ë©”ì¼ ë¶„ì„"""
        data = self.data_hub.get_cached(user_id)
        emails = [d for d in data if d.type == DataType.EMAIL]
        
        if not emails:
            return []
        
        results = []
        
        # 1. ìš°ì„ ìˆœìœ„ ë¶„ë¥˜
        priority_result = self._classify_email_priority(emails)
        results.append(AnalysisResult(
            type=AnalysisType.PRIORITY,
            data_type=DataType.EMAIL,
            result=priority_result,
            confidence=0.85
        ))
        
        # 2. ìš”ì•½ ìƒì„±
        summary_result = self._summarize_emails(emails)
        results.append(AnalysisResult(
            type=AnalysisType.SUMMARY,
            data_type=DataType.EMAIL,
            result=summary_result,
            confidence=0.9
        ))
        
        return results
    
    async def analyze_calendar(self, user_id: str) -> List[AnalysisResult]:
        """ìº˜ë¦°ë” ë¶„ì„"""
        data = self.data_hub.get_cached(user_id)
        events = [d for d in data if d.type == DataType.CALENDAR]
        
        if not events:
            return []
        
        results = []
        
        # ì¼ì • ìµœì í™” ì œì•ˆ
        optimization = self._optimize_schedule(events)
        results.append(AnalysisResult(
            type=AnalysisType.RECOMMENDATION,
            data_type=DataType.CALENDAR,
            result=optimization,
            confidence=0.8
        ))
        
        return results
    
    async def analyze_messages(self, user_id: str) -> List[AnalysisResult]:
        """ë©”ì‹œì§€ ë¶„ì„"""
        data = self.data_hub.get_cached(user_id)
        messages = [d for d in data if d.type == DataType.MESSAGE]
        
        if not messages:
            return []
        
        results = []
        
        # ê°ì„± ë¶„ì„
        sentiment = self._analyze_sentiment(messages)
        results.append(AnalysisResult(
            type=AnalysisType.SENTIMENT,
            data_type=DataType.MESSAGE,
            result=sentiment,
            confidence=0.75
        ))
        
        return results
    
    async def analyze_all(self, user_id: str) -> Dict[str, List[AnalysisResult]]:
        """ì „ì²´ ë¶„ì„"""
        return {
            "emails": await self.analyze_emails(user_id),
            "calendar": await self.analyze_calendar(user_id),
            "messages": await self.analyze_messages(user_id),
        }
    
    async def generate_daily_brief(self, user_id: str) -> Dict[str, Any]:
        """ì¼ì¼ ë¸Œë¦¬í•‘ ìƒì„±"""
        data = self.data_hub.get_cached(user_id)
        summary = self.data_hub.get_summary(user_id)
        
        # ì˜¤ëŠ˜ ì¼ì •
        today = datetime.utcnow().date()
        today_events = []
        for d in data:
            if d.type == DataType.CALENDAR:
                event_date = d.metadata.get("start", "")
                if event_date and str(today) in event_date:
                    today_events.append({
                        "title": d.title,
                        "time": event_date,
                        "location": d.metadata.get("location", "")
                    })
        
        # ì¤‘ìš” ì´ë©”ì¼
        important_emails = []
        for d in data:
            if d.type == DataType.EMAIL:
                # ê°„ë‹¨í•œ ìš°ì„ ìˆœìœ„ íŒë‹¨
                if any(kw in d.title.lower() for kw in ["urgent", "ê¸´ê¸‰", "asap", "important", "ì¤‘ìš”"]):
                    important_emails.append({
                        "title": d.title,
                        "from": d.metadata.get("from", ""),
                        "preview": d.content[:100]
                    })
        
        # ìµœê·¼ ë©”ì‹œì§€ ìš”ì•½
        recent_messages = []
        for d in data:
            if d.type == DataType.MESSAGE:
                recent_messages.append({
                    "channel": d.title,
                    "content": d.content[:100]
                })
        
        return {
            "date": str(today),
            "summary": {
                "total_items": summary.get("total", 0),
                "by_type": summary.get("by_type", {})
            },
            "today_events": today_events[:5],
            "important_emails": important_emails[:5],
            "recent_messages": recent_messages[:5],
            "recommendations": self._generate_recommendations(data)
        }
    
    # ============================================
    # Private Methods (Rule-based, LLM ì—°ë™ ê°€ëŠ¥)
    # ============================================
    
    def _classify_email_priority(self, emails: List[UnifiedData]) -> Dict:
        """ì´ë©”ì¼ ìš°ì„ ìˆœìœ„ ë¶„ë¥˜"""
        high = []
        medium = []
        low = []
        
        high_keywords = ["urgent", "ê¸´ê¸‰", "asap", "important", "ì¤‘ìš”", "deadline", "ë§ˆê°"]
        low_keywords = ["newsletter", "ë‰´ìŠ¤ë ˆí„°", "unsubscribe", "ìˆ˜ì‹ ê±°ë¶€", "promotion", "ê´‘ê³ "]
        
        for email in emails:
            title_lower = email.title.lower()
            content_lower = email.content.lower()
            
            if any(kw in title_lower or kw in content_lower for kw in high_keywords):
                high.append(email.id)
            elif any(kw in title_lower or kw in content_lower for kw in low_keywords):
                low.append(email.id)
            else:
                medium.append(email.id)
        
        return {
            "high": len(high),
            "medium": len(medium),
            "low": len(low),
            "high_ids": high[:10],
            "low_ids": low[:10]
        }
    
    def _summarize_emails(self, emails: List[UnifiedData]) -> Dict:
        """ì´ë©”ì¼ ìš”ì•½"""
        # ë°œì‹ ìžë³„ ê·¸ë£¹í•‘
        by_sender = {}
        for email in emails:
            sender = email.metadata.get("from", "unknown")
            if sender not in by_sender:
                by_sender[sender] = []
            by_sender[sender].append(email.title)
        
        # ìƒìœ„ ë°œì‹ ìž
        top_senders = sorted(by_sender.items(), key=lambda x: len(x[1]), reverse=True)[:5]
        
        return {
            "total_emails": len(emails),
            "unique_senders": len(by_sender),
            "top_senders": [
                {"sender": s[0], "count": len(s[1]), "subjects": s[1][:3]}
                for s in top_senders
            ]
        }
    
    def _optimize_schedule(self, events: List[UnifiedData]) -> Dict:
        """ì¼ì • ìµœì í™”"""
        recommendations = []
        
        # ì—°ì† íšŒì˜ ê°ì§€
        sorted_events = sorted(events, key=lambda e: e.metadata.get("start", ""))
        
        for i, event in enumerate(sorted_events):
            if i > 0:
                prev_end = sorted_events[i-1].metadata.get("end", "")
                curr_start = event.metadata.get("start", "")
                
                # íœ´ì‹ ì—†ëŠ” ì—°ì† íšŒì˜
                if prev_end and curr_start and prev_end >= curr_start:
                    recommendations.append({
                        "type": "back_to_back",
                        "message": f"'{sorted_events[i-1].title}'ì™€ '{event.title}' ì‚¬ì´ì— íœ´ì‹ì´ í•„ìš”í•©ë‹ˆë‹¤",
                        "events": [sorted_events[i-1].id, event.id]
                    })
        
        # ë¹ˆ ì‹œê°„ëŒ€ ë¶„ì„
        return {
            "total_events": len(events),
            "recommendations": recommendations[:5],
            "busy_days": self._find_busy_days(events)
        }
    
    def _find_busy_days(self, events: List[UnifiedData]) -> List[str]:
        """ë°”ìœ ë‚  ì°¾ê¸°"""
        by_date = {}
        for event in events:
            date_str = event.metadata.get("start", "")[:10]
            if date_str:
                by_date[date_str] = by_date.get(date_str, 0) + 1
        
        busy = [date for date, count in by_date.items() if count >= 5]
        return sorted(busy)[:5]
    
    def _analyze_sentiment(self, messages: List[UnifiedData]) -> Dict:
        """ê°ì„± ë¶„ì„"""
        positive_words = ["ì¢‹ì•„", "ê°ì‚¬", "ì¶•í•˜", "great", "awesome", "thanks", "good", "ðŸ‘", "ðŸŽ‰"]
        negative_words = ["ë¬¸ì œ", "ì´ìŠˆ", "ë²„ê·¸", "error", "issue", "problem", "fail", "ðŸ˜¢", "ðŸ˜ "]
        
        positive = 0
        negative = 0
        neutral = 0
        
        for msg in messages:
            content = msg.content.lower()
            
            pos_score = sum(1 for w in positive_words if w in content)
            neg_score = sum(1 for w in negative_words if w in content)
            
            if pos_score > neg_score:
                positive += 1
            elif neg_score > pos_score:
                negative += 1
            else:
                neutral += 1
        
        total = len(messages)
        return {
            "positive": positive,
            "negative": negative,
            "neutral": neutral,
            "positive_rate": positive / total * 100 if total else 0,
            "overall": "positive" if positive > negative else "negative" if negative > positive else "neutral"
        }
    
    def _generate_recommendations(self, data: List[UnifiedData]) -> List[str]:
        """ì¶”ì²œ ìƒì„±"""
        recommendations = []
        
        # ì½ì§€ ì•Šì€ ì´ë©”ì¼
        unread_emails = sum(1 for d in data if d.type == DataType.EMAIL)
        if unread_emails > 20:
            recommendations.append(f"ðŸ“§ {unread_emails}ê°œì˜ ì´ë©”ì¼ì´ ìžˆìŠµë‹ˆë‹¤. ì •ë¦¬ê°€ í•„ìš”í•´ ë³´ìž…ë‹ˆë‹¤.")
        
        # ì˜¤ëŠ˜ ì¼ì •
        today = datetime.utcnow().date()
        today_events = sum(1 for d in data if d.type == DataType.CALENDAR and str(today) in d.metadata.get("start", ""))
        if today_events >= 5:
            recommendations.append(f"ðŸ“… ì˜¤ëŠ˜ {today_events}ê°œì˜ ì¼ì •ì´ ìžˆìŠµë‹ˆë‹¤. ë°”ìœ í•˜ë£¨ê°€ ë  ê²ƒ ê°™ë„¤ìš”!")
        
        # ë¯¸ë‹µë³€ ë©”ì‹œì§€
        messages = [d for d in data if d.type == DataType.MESSAGE]
        if messages:
            recommendations.append(f"ðŸ’¬ {len(messages)}ê°œì˜ ìƒˆ ë©”ì‹œì§€ë¥¼ í™•ì¸í•˜ì„¸ìš”.")
        
        return recommendations


# ============================================
# Singleton
# ============================================

_analyzer: Optional[AIAnalyzer] = None

def get_analyzer() -> AIAnalyzer:
    global _analyzer
    if _analyzer is None:
        _analyzer = AIAnalyzer()
    return _analyzer
