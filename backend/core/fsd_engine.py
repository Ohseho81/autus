"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš€ AUTUS FSD Engine v2.0.0 (ì§€ëŠ¥ ë°°í¬ ì—”ì§„)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

Full Self-Distribution Engine - 8ì–µ ëª… ëŒ€ìƒ ì§€ëŠ¥ ë°°í¬

í”„ë¡œì„¸ìŠ¤:
1. Ingest: ì‚¬ìš©ì ë°ì´í„° ìˆ˜ì§‘
2. Prune: 99%ì˜ ë…¸ì´ì¦ˆ ì‚­ì œ (Zero Meaning)
3. Align: 1%ì˜ ì •ìˆ˜ë¥¼ 36ê°œ ë…¸ë“œì— ë°°ì¹˜
4. Resonate: ì•°ë¹„ì–¸íŠ¸ ë°°í¬
5. Stillness: ì—”íŠ¸ë¡œí”¼ 0 ìœ ì§€

"ë§ˆìŠ¤í„°ì˜ ì •ë‹µ ë²¡í„°ê°€ ì‚¬ìš©ì ê¸°ê¸°ì— ì‹¤ì‹œê°„ìœ¼ë¡œ íë¥´ëŠ” 'ì§€ëŠ¥ ìŠ¤íŠ¸ë¦¬ë°'"
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

import numpy as np
from typing import Dict, List, Optional, Tuple, Any
from dataclasses import dataclass, field
from datetime import datetime
from enum import Enum
import hashlib

from .master_hub import (
    MasterRegistry,
    get_master_registry,
    Domain,
    DOMAINS,
    SECTORS,
    VECTOR_DIM,
)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ìƒìˆ˜ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# ì—”íŠ¸ë¡œí”¼ ì„ê³„ê°’ (Zero Meaning ê¸°ì¤€)
ENTROPY_THRESHOLD = 0.144

# ìµœì†Œ ì‹ í˜¸ ê°•ë„ (ì´ ë¯¸ë§Œì€ ë…¸ì´ì¦ˆë¡œ ê°„ì£¼)
MIN_SIGNAL_STRENGTH = 0.05

# ê³µëª… ì¦í­ ë°°ìœ¨
RESONANCE_AMPLIFICATION = 1.12


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì²˜ë¦¬ ê²°ê³¼ ë°ì´í„° êµ¬ì¡°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ProcessingStage(Enum):
    """ì²˜ë¦¬ ë‹¨ê³„"""
    INGEST = "ingest"
    PRUNE = "prune"
    ALIGN = "align"
    RESONATE = "resonate"
    STILLNESS = "stillness"


@dataclass
class ProcessingResult:
    """ì²˜ë¦¬ ê²°ê³¼"""
    success: bool
    stage: ProcessingStage
    input_vector: np.ndarray = None
    output_vector: np.ndarray = None
    optimal_trajectory: np.ndarray = None
    
    # ë©”íŠ¸ë¦­
    noise_removed: float = 0.0
    signal_strength: float = 0.0
    resonance_score: float = 0.0
    entropy_delta: float = 0.0
    
    # ë§¤í•‘ ì •ë³´
    matched_domain: Optional[str] = None
    matched_nodes: List[str] = field(default_factory=list)
    
    # ë©”íƒ€ë°ì´í„°
    processing_time_ms: float = 0.0
    timestamp: datetime = field(default_factory=datetime.utcnow)
    
    def to_dict(self) -> Dict:
        return {
            "success": self.success,
            "stage": self.stage.value,
            "metrics": {
                "noise_removed": self.noise_removed,
                "signal_strength": self.signal_strength,
                "resonance_score": self.resonance_score,
                "entropy_delta": self.entropy_delta,
            },
            "mapping": {
                "domain": self.matched_domain,
                "nodes": self.matched_nodes,
            },
            "processing_time_ms": self.processing_time_ms,
            "timestamp": self.timestamp.isoformat(),
        }


@dataclass
class OptimalTrajectory:
    """ìµœì  ê²½ë¡œ (ì‚¬ìš©ìì—ê²Œ ë°°í¬ë  'ë³´ì´ì§€ ì•ŠëŠ” ë ˆì¼')"""
    user_id: str
    current_position: np.ndarray
    target_position: np.ndarray
    path_vectors: List[np.ndarray]
    
    # ê°€ì´ë“œ ë©”íƒ€ë°ì´í„°
    primary_domain: str
    suggested_actions: List[str]
    confidence: float = 0.0
    
    def to_dict(self) -> Dict:
        return {
            "user_id": self.user_id,
            "primary_domain": self.primary_domain,
            "suggested_actions": self.suggested_actions,
            "confidence": self.confidence,
            "path_length": len(self.path_vectors),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FSD ì—”ì§„ (8ì–µ ëª… ì§€ëŠ¥ ë°°í¬)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FSDEngine:
    """
    Full Self-Distribution Engine
    
    ë§ˆìŠ¤í„°ì˜ ì§€ëŠ¥ì„ 8ì–µ ëª…ì—ê²Œ ì‹¤ì‹œê°„ ë°°í¬
    """
    
    def __init__(self, registry: Optional[MasterRegistry] = None):
        """
        Args:
            registry: ë§ˆìŠ¤í„° ë ˆì§€ìŠ¤íŠ¸ë¦¬ (ì—†ìœ¼ë©´ ì‹±ê¸€í„´ ì‚¬ìš©)
        """
        self.registry = registry or get_master_registry()
        
        # í†µê³„
        self._stats = {
            "total_processed": 0,
            "total_pruned": 0,
            "total_aligned": 0,
            "total_distributed": 0,
            "average_noise_ratio": 0.0,
        }
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë©”ì¸ íŒŒì´í”„ë¼ì¸
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def process_human_input(
        self,
        user_vector: np.ndarray,
        user_id: Optional[str] = None,
    ) -> ProcessingResult:
        """
        80ì–µ ëª…ì˜ ì…ë ¥ì„ ì‹¤ì‹œê°„ ì²˜ë¦¬ (ëª¨ìœ¼ê¸°-ì‚­ì œí•˜ê¸°-ì •ë¦¬í•˜ê¸°)
        
        Args:
            user_vector: ì‚¬ìš©ì ì…ë ¥ ë²¡í„° (512ì°¨ì›)
            user_id: ì‚¬ìš©ì ID
        
        Returns:
            ProcessingResult
        """
        start_time = datetime.utcnow()
        
        # ì…ë ¥ ê²€ì¦
        if user_vector is None or len(user_vector) != VECTOR_DIM:
            return ProcessingResult(
                success=False,
                stage=ProcessingStage.INGEST,
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 1: INGEST (ëª¨ìœ¼ê¸°)
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        input_vector = user_vector.copy()
        original_norm = np.linalg.norm(input_vector)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 2: PRUNE (ì‚­ì œí•˜ê¸°) - Zero Meaning í•„í„°
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        clean_vector, noise_removed = self._apply_zero_meaning(input_vector)
        signal_strength = np.linalg.norm(clean_vector) / (original_norm + 1e-10)
        
        # ì‹ í˜¸ê°€ ë„ˆë¬´ ì•½í•˜ë©´ ì²˜ë¦¬ ì¤‘ë‹¨
        if signal_strength < MIN_SIGNAL_STRENGTH:
            return ProcessingResult(
                success=False,
                stage=ProcessingStage.PRUNE,
                input_vector=input_vector,
                noise_removed=noise_removed,
                signal_strength=signal_strength,
            )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 3: ALIGN (ì •ë¦¬í•˜ê¸°) - ë…¸ë“œ ë§¤í•‘
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        matched_domain, matched_nodes = self._align_to_nodes(clean_vector)
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 4: RESONATE (ê³µëª…) - ìµœì  ê²½ë¡œ ê³„ì‚°
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        consensus = self.registry.get_global_consensus()
        optimal_trajectory, resonance_score = self._calculate_optimal_trajectory(
            clean_vector, consensus, matched_domain
        )
        
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        # Stage 5: STILLNESS (ê³ ìš”) - ì—”íŠ¸ë¡œí”¼ ì¸¡ì •
        # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        entropy_delta = self._calculate_entropy_delta(input_vector, optimal_trajectory)
        
        # ì²˜ë¦¬ ì‹œê°„ ê³„ì‚°
        processing_time = (datetime.utcnow() - start_time).total_seconds() * 1000
        
        # í†µê³„ ì—…ë°ì´íŠ¸
        self._stats["total_processed"] += 1
        self._stats["total_aligned"] += 1
        
        return ProcessingResult(
            success=True,
            stage=ProcessingStage.STILLNESS,
            input_vector=input_vector,
            output_vector=clean_vector,
            optimal_trajectory=optimal_trajectory,
            noise_removed=noise_removed,
            signal_strength=signal_strength,
            resonance_score=resonance_score,
            entropy_delta=entropy_delta,
            matched_domain=matched_domain,
            matched_nodes=matched_nodes,
            processing_time_ms=processing_time,
        )
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Zero Meaning í•„í„° (ì—”íŠ¸ë¡œí”¼ ê¸°ë°˜ ë…¸ì´ì¦ˆ ì œê±°)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def _apply_zero_meaning(self, vector: np.ndarray) -> Tuple[np.ndarray, float]:
        """
        Zero Meaning í•„í„°: ì—”íŠ¸ë¡œí”¼ê°€ ë†’ì€ ë…¸ì´ì¦ˆ ì„±ë¶„ ì œê±°
        
        ì›ë¦¬:
        - ì„ê³„ê°’(0.144) ë¯¸ë§Œì˜ ì•½í•œ ì‹ í˜¸ëŠ” ë…¸ì´ì¦ˆë¡œ ê°„ì£¼í•˜ì—¬ 0ìœ¼ë¡œ ìˆ˜ë ´
        - ê°•í•œ ì‹ í˜¸ë§Œ ë‚¨ê²¨ 'ë³¸ì§ˆ'ì„ ì¶”ì¶œ
        
        Args:
            vector: ì…ë ¥ ë²¡í„°
        
        Returns:
            (ì •ì œëœ ë²¡í„°, ì œê±°ëœ ë…¸ì´ì¦ˆ ë¹„ìœ¨)
        """
        clean_vector = vector.copy()
        
        # ì ˆëŒ€ê°’ì´ ì„ê³„ê°’ ë¯¸ë§Œì¸ ì„±ë¶„ì„ 0ìœ¼ë¡œ
        noise_mask = np.abs(clean_vector) < ENTROPY_THRESHOLD
        noise_count = np.sum(noise_mask)
        clean_vector[noise_mask] = 0
        
        # ë…¸ì´ì¦ˆ ì œê±° ë¹„ìœ¨
        noise_removed = noise_count / len(vector)
        
        # L2 ì •ê·œí™” (ì—ë„ˆì§€ ë³´ì¡´)
        norm = np.linalg.norm(clean_vector)
        if norm > 0:
            clean_vector = clean_vector / norm
        
        return clean_vector, noise_removed
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë…¸ë“œ ì •ë ¬ (36ê°œ ë…¸ë“œì— ë§¤í•‘)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def _align_to_nodes(self, vector: np.ndarray) -> Tuple[str, List[str]]:
        """
        ë²¡í„°ë¥¼ 36ê°œ ë…¸ë“œì— ì •ë ¬
        
        Args:
            vector: ì •ì œëœ ë²¡í„°
        
        Returns:
            (ì£¼ìš” ë„ë©”ì¸, ë§¤í•‘ëœ ë…¸ë“œ ID ë¦¬ìŠ¤íŠ¸)
        """
        # ê¸€ë¡œë²Œ í•©ì˜ ë¡œë“œ
        consensus = self.registry.get_global_consensus()
        
        # ê° ë„ë©”ì¸ê³¼ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        domain_scores = {}
        for d in range(DOMAINS):
            domain_consensus = np.mean(consensus[d], axis=0)
            if np.linalg.norm(domain_consensus) > 0:
                similarity = np.dot(vector, domain_consensus) / (
                    np.linalg.norm(vector) * np.linalg.norm(domain_consensus) + 1e-10
                )
                domain_scores[d] = similarity
            else:
                domain_scores[d] = 0.0
        
        # ê°€ì¥ ìœ ì‚¬í•œ ë„ë©”ì¸ ì„ íƒ
        best_domain_id = max(domain_scores, key=domain_scores.get)
        best_domain = list(Domain)[best_domain_id]
        
        # í•´ë‹¹ ë„ë©”ì¸ì˜ ë…¸ë“œ ID ìƒì„± (3ê°œ ë…¸ë“œ)
        base_node_id = best_domain_id * 3 + 1
        matched_nodes = [f"n{base_node_id + i:02d}" for i in range(3)]
        
        return best_domain.code, matched_nodes
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ìµœì  ê²½ë¡œ ê³„ì‚° (FSD í•µì‹¬)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def _calculate_optimal_trajectory(
        self,
        user_vector: np.ndarray,
        consensus: np.ndarray,
        domain_code: str,
    ) -> Tuple[np.ndarray, float]:
        """
        ì‚¬ìš©ìì˜ í˜„ì¬ ìƒíƒœì™€ ë§ˆìŠ¤í„° í•©ì˜ë¥¼ ë¹„êµí•˜ì—¬ ìµœì  ê²½ë¡œ ê³„ì‚°
        
        ì´ê²ƒì´ ì‚¬ìš©ìì—ê²Œ 'ë³´ì´ì§€ ì•ŠëŠ” ë ˆì¼'ë¡œ ì œê³µë˜ëŠ” ê°€ì´ë“œ
        
        Args:
            user_vector: ì‚¬ìš©ì í˜„ì¬ ìƒíƒœ ë²¡í„°
            consensus: ê¸€ë¡œë²Œ í•©ì˜ ë²¡í„° [12, 12, 512]
            domain_code: ë§¤í•‘ëœ ë„ë©”ì¸ ì½”ë“œ
        
        Returns:
            (ìµœì  ê²½ë¡œ ë²¡í„°, ê³µëª… ì ìˆ˜)
        """
        # ë„ë©”ì¸ ID ì°¾ê¸°
        domain_id = None
        for d, domain_enum in enumerate(Domain):
            if domain_enum.code == domain_code:
                domain_id = d
                break
        
        if domain_id is None:
            return user_vector, 0.0
        
        # í•´ë‹¹ ë„ë©”ì¸ì˜ í•©ì˜ (12ê°œ ì„¹í„° í‰ê· )
        domain_consensus = np.mean(consensus[domain_id], axis=0)
        
        if np.linalg.norm(domain_consensus) < 0.1:
            # í•©ì˜ê°€ ì—†ìœ¼ë©´ í˜„ì¬ ë²¡í„° ê·¸ëŒ€ë¡œ ë°˜í™˜
            return user_vector, 0.0
        
        # ìµœì  ê²½ë¡œ = í˜„ì¬ ìƒíƒœì—ì„œ í•©ì˜ ë°©í–¥ìœ¼ë¡œì˜ ë²¡í„°
        direction = domain_consensus - user_vector
        
        # ê³µëª… ì¦í­ ì ìš©
        optimal_trajectory = user_vector + direction * RESONANCE_AMPLIFICATION
        
        # L2 ì •ê·œí™”
        norm = np.linalg.norm(optimal_trajectory)
        if norm > 0:
            optimal_trajectory = optimal_trajectory / norm
        
        # ê³µëª… ì ìˆ˜ = í˜„ì¬ ìƒíƒœì™€ í•©ì˜ì˜ ìœ ì‚¬ë„
        resonance_score = np.dot(user_vector, domain_consensus) / (
            np.linalg.norm(user_vector) * np.linalg.norm(domain_consensus) + 1e-10
        )
        
        return optimal_trajectory, float(resonance_score)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ì—”íŠ¸ë¡œí”¼ ê³„ì‚°
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def _calculate_entropy_delta(
        self,
        original: np.ndarray,
        optimized: np.ndarray,
    ) -> float:
        """
        ì›ë³¸ê³¼ ìµœì í™”ëœ ë²¡í„° ê°„ì˜ ì—”íŠ¸ë¡œí”¼ ë³€í™” ê³„ì‚°
        
        ìŒìˆ˜: ì—”íŠ¸ë¡œí”¼ ê°ì†Œ (ì¢‹ìŒ - ë” ì •ë ¬ë¨)
        ì–‘ìˆ˜: ì—”íŠ¸ë¡œí”¼ ì¦ê°€ (ë‚˜ì¨ - ë” í˜¼ë€ìŠ¤ëŸ¬ì›€)
        """
        # ë²¡í„°ì˜ ë¶„ì‚°ì„ ì—”íŠ¸ë¡œí”¼ ëŒ€ìš©ìœ¼ë¡œ ì‚¬ìš©
        original_entropy = np.var(original)
        optimized_entropy = np.var(optimized)
        
        return optimized_entropy - original_entropy
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ë°°ì¹˜ ì²˜ë¦¬ (ëŒ€ê·œëª¨ íŠ¸ë˜í”½ìš©)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def process_batch(
        self,
        vectors: List[np.ndarray],
        user_ids: Optional[List[str]] = None,
    ) -> List[ProcessingResult]:
        """
        ë°°ì¹˜ ì²˜ë¦¬ (8ì–µ ëª… íŠ¸ë˜í”½ ëŒ€ì‘)
        
        Args:
            vectors: ì‚¬ìš©ì ë²¡í„° ë¦¬ìŠ¤íŠ¸
            user_ids: ì‚¬ìš©ì ID ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ì²˜ë¦¬ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        if user_ids is None:
            user_ids = [None] * len(vectors)
        
        results = []
        for vector, user_id in zip(vectors, user_ids):
            result = self.process_human_input(vector, user_id)
            results.append(result)
        
        return results
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í†µê³„
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    def get_stats(self) -> Dict[str, Any]:
        """ì—”ì§„ í†µê³„"""
        return {
            **self._stats,
            "registry_stats": self.registry.get_registry_stats(),
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ì‹±ê¸€í„´ ì¸ìŠ¤í„´ìŠ¤
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_engine: Optional[FSDEngine] = None


def get_fsd_engine() -> FSDEngine:
    """FSD ì—”ì§„ ì‹±ê¸€í„´"""
    global _engine
    if _engine is None:
        _engine = FSDEngine()
    return _engine


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë‚´ë³´ë‚´ê¸°
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

__all__ = [
    "FSDEngine",
    "ProcessingResult",
    "ProcessingStage",
    "OptimalTrajectory",
    "get_fsd_engine",
    "ENTROPY_THRESHOLD",
]
