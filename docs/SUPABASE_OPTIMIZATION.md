# ğŸš€ Supabase ìµœì í™” ìŠ¤í™ (3K â†’ 100ë§Œëª… ëŒ€ì‘)

**ëª©í‘œ**: 100ë§Œëª… ê·œëª¨ì—ì„œë„ 99.9% ê°€ìš©ì„±, 100ms ì´í•˜ ì‘ë‹µ ì†ë„ ë‹¬ì„±

---

## ğŸ“Š í˜„ì¬ ìŠ¤í‚¤ë§ˆ ë¶„ì„

### ê¸°ì¡´ í…Œì´ë¸” (5ê°œ)
```
profiles          - í•™ìƒ/ë¶€ëª¨/ì½”ì¹˜ (3,000 â†’ 100,000 â†’ 1,000,000 rows)
payments          - ê²°ì œ ê¸°ë³¸ ì •ë³´ (ì›” 3,000 â†’ 100,000ê±´)
schedules         - ìˆ˜ì—… ì¼ì • (50 â†’ 500ê°œ ê³ ì •)
bookings          - ìˆ˜ì—… ì˜ˆì•½ (ì›” 10,000 â†’ 500,000ê±´)
notifications     - ì•Œë¦¼ (7ì¼ TTL, í•­ìƒ ~10,000ê±´ ìœ ì§€)
```

### ì‹ ê·œ í…Œì´ë¸” (4ê°œ) - ê²°ì œì„ ìƒ í†µí•©
```
invoices              - ì²­êµ¬ì„œ (ì›” 3,000 â†’ 100,000ê±´)
payment_transactions  - ê²°ì œ ë‚´ì—­ (ì›” 3,000 â†’ 100,000ê±´)
cash_receipts         - í˜„ê¸ˆì˜ìˆ˜ì¦ (ì›” 500 â†’ 20,000ê±´)
business_settings     - ì‚¬ì—…ì¥ ì •ë³´ (1ê±´ ê³ ì •)
```

---

## ğŸ¯ ì„±ëŠ¥ ëª©í‘œ (ê·œëª¨ë³„)

| ê·œëª¨ | í•™ìƒ ìˆ˜ | ì›”ê°„ íŠ¸ëœì­ì…˜ | API ì‘ë‹µ | DB ì‘ë‹µ | ë™ì‹œ ì ‘ì† |
|------|--------|-------------|---------|---------|----------|
| **Phase 1** | 3,000ëª… | 10,000ê±´ | <100ms | <50ms | 100 |
| **Phase 2** | 10,000ëª… | 50,000ê±´ | <150ms | <75ms | 500 |
| **Phase 3** | 100,000ëª… | 500,000ê±´ | <200ms | <100ms | 5,000 |
| **Phase 4** | 1,000,000ëª… | 5,000,000ê±´ | <300ms | <150ms | 50,000 |

---

## ğŸ”§ ìµœì í™” ì „ëµ (ë‹¨ê³„ë³„)

### Phase 1: ê¸°ë³¸ ìµœì í™” (3K â†’ 10K) - Week 2-3

#### 1ï¸âƒ£ ì¸ë±ìŠ¤ ìµœì í™”

```sql
-- ===== profiles í…Œì´ë¸” =====
CREATE INDEX idx_profiles_type ON profiles(type);
CREATE INDEX idx_profiles_status ON profiles(status);
CREATE INDEX idx_profiles_parent ON profiles(parent_id);
CREATE INDEX idx_profiles_phone ON profiles(phone);  -- ì „í™”ë²ˆí˜¸ ê²€ìƒ‰ (ì¹´ì¹´ì˜¤í†¡ ë°œì†¡)
CREATE INDEX idx_profiles_external_id ON profiles(external_id);  -- ì™¸ë¶€ ì‹œìŠ¤í…œ ì—°ë™

-- Composite Index (ë³µí•© ê²€ìƒ‰)
CREATE INDEX idx_profiles_type_status ON profiles(type, status);

-- ===== payments í…Œì´ë¸” =====
CREATE INDEX idx_payments_student ON payments(student_id);
CREATE INDEX idx_payments_status ON payments(payment_status);
CREATE INDEX idx_payments_due_date ON payments(due_date);
CREATE INDEX idx_payments_invoice_date ON payments(invoice_date);

-- ë¯¸ìˆ˜ê¸ˆ ì¡°íšŒ ìµœì í™”
CREATE INDEX idx_payments_unpaid ON payments(payment_status, due_date)
  WHERE paid_amount < total_amount;

-- ===== bookings í…Œì´ë¸” =====
CREATE INDEX idx_bookings_student ON bookings(student_id);
CREATE INDEX idx_bookings_schedule ON bookings(schedule_id);
CREATE INDEX idx_bookings_date ON bookings(booking_date);
CREATE INDEX idx_bookings_status ON bookings(status);

-- ë³µí•© ì¸ë±ìŠ¤: íŠ¹ì • ë‚ ì§œ íŠ¹ì • í•™ìƒ ì¡°íšŒ
CREATE INDEX idx_bookings_student_date ON bookings(student_id, booking_date);
CREATE INDEX idx_bookings_schedule_date ON bookings(schedule_id, booking_date);

-- ===== invoices í…Œì´ë¸” =====
CREATE INDEX idx_invoices_student ON invoices(student_id);
CREATE INDEX idx_invoices_parent ON invoices(parent_id);
CREATE INDEX idx_invoices_status ON invoices(status);
CREATE INDEX idx_invoices_due_date ON invoices(due_date);
CREATE INDEX idx_invoices_sent_at ON invoices(sent_at);

-- ë¯¸ë‚© ì²­êµ¬ì„œ ì¡°íšŒ ìµœì í™”
CREATE INDEX idx_invoices_unpaid ON invoices(status, due_date)
  WHERE status IN ('sent', 'partial', 'overdue');

-- ===== payment_transactions í…Œì´ë¸” =====
CREATE INDEX idx_payment_transactions_invoice ON payment_transactions(invoice_id);
CREATE INDEX idx_payment_transactions_student ON payment_transactions(student_id);
CREATE INDEX idx_payment_transactions_paid_at ON payment_transactions(paid_at);
CREATE INDEX idx_payment_transactions_status ON payment_transactions(status);
CREATE INDEX idx_payment_transactions_card_company ON payment_transactions(card_company);

-- ë§¤ì¶œ ì¡°íšŒ ìµœì í™” (ì¼ìë³„)
CREATE INDEX idx_payment_transactions_paid_date ON payment_transactions(DATE(paid_at));

-- ===== notifications í…Œì´ë¸” =====
CREATE INDEX idx_notifications_profile ON notifications(profile_id);
CREATE INDEX idx_notifications_status ON notifications(status);
CREATE INDEX idx_notifications_created_at ON notifications(created_at);
CREATE INDEX idx_notifications_expires_at ON notifications(expires_at);

-- ë§Œë£Œëœ ì•Œë¦¼ ìë™ ì‚­ì œìš©
CREATE INDEX idx_notifications_expired ON notifications(expires_at)
  WHERE status = 'delivered';
```

#### 2ï¸âƒ£ RLS (Row Level Security) ì •ì±…

```sql
-- ===== profiles í…Œì´ë¸” RLS =====

-- Service Role: ì „ì²´ ì ‘ê·¼
CREATE POLICY "service_role_all_profiles"
  ON profiles
  FOR ALL
  TO service_role
  USING (true)
  WITH CHECK (true);

-- Authenticated Users: ë³¸ì¸ ë° ìë…€ë§Œ ì¡°íšŒ
CREATE POLICY "users_view_own_profile"
  ON profiles
  FOR SELECT
  TO authenticated
  USING (
    auth.uid()::text = id::text OR
    auth.uid()::text = parent_id::text
  );

-- Coach: ë‹´ë‹¹ í•™ìƒë§Œ ì¡°íšŒ
CREATE POLICY "coaches_view_students"
  ON profiles
  FOR SELECT
  TO authenticated
  USING (
    type = 'student' AND
    EXISTS (
      SELECT 1 FROM schedules
      WHERE coach_id = auth.uid()::uuid
    )
  );

-- ===== payments í…Œì´ë¸” RLS =====

-- Service Role: ì „ì²´ ì ‘ê·¼
CREATE POLICY "service_role_all_payments"
  ON payments
  FOR ALL
  TO service_role
  USING (true)
  WITH CHECK (true);

-- í•™ìƒ/ë¶€ëª¨: ë³¸ì¸ ê²°ì œë§Œ ì¡°íšŒ
CREATE POLICY "users_view_own_payments"
  ON payments
  FOR SELECT
  TO authenticated
  USING (
    student_id IN (
      SELECT id FROM profiles
      WHERE id = auth.uid()::uuid OR parent_id = auth.uid()::uuid
    )
  );

-- ===== bookings í…Œì´ë¸” RLS =====

-- Service Role: ì „ì²´ ì ‘ê·¼
CREATE POLICY "service_role_all_bookings"
  ON bookings
  FOR ALL
  TO service_role
  USING (true)
  WITH CHECK (true);

-- í•™ìƒ/ë¶€ëª¨: ë³¸ì¸ ì˜ˆì•½ë§Œ ì¡°íšŒ/ìƒì„±
CREATE POLICY "users_manage_own_bookings"
  ON bookings
  FOR ALL
  TO authenticated
  USING (
    student_id IN (
      SELECT id FROM profiles
      WHERE id = auth.uid()::uuid OR parent_id = auth.uid()::uuid
    )
  )
  WITH CHECK (
    student_id IN (
      SELECT id FROM profiles
      WHERE id = auth.uid()::uuid OR parent_id = auth.uid()::uuid
    )
  );

-- ===== invoices í…Œì´ë¸” RLS =====

-- Service Role: ì „ì²´ ì ‘ê·¼
CREATE POLICY "service_role_all_invoices"
  ON invoices
  FOR ALL
  TO service_role
  USING (true)
  WITH CHECK (true);

-- í•™ìƒ/ë¶€ëª¨: ë³¸ì¸ ì²­êµ¬ì„œë§Œ ì¡°íšŒ
CREATE POLICY "users_view_own_invoices"
  ON invoices
  FOR SELECT
  TO authenticated
  USING (
    student_id IN (
      SELECT id FROM profiles
      WHERE id = auth.uid()::uuid OR parent_id = auth.uid()::uuid
    )
  );
```

#### 3ï¸âƒ£ ì¿¼ë¦¬ ìµœì í™”

```sql
-- ===== Materialized View: ìì£¼ ì¡°íšŒë˜ëŠ” ì§‘ê³„ ë°ì´í„° =====

-- 1. í•™ìƒë³„ ë¯¸ìˆ˜ê¸ˆ í˜„í™©
CREATE MATERIALIZED VIEW mv_student_unpaid_summary AS
SELECT
  p.student_id,
  prof.name,
  prof.phone,
  COUNT(p.id) as unpaid_count,
  SUM(p.total_amount - p.paid_amount) as total_unpaid,
  MIN(p.due_date) as earliest_due_date,
  MAX(p.due_date) as latest_due_date
FROM payments p
JOIN profiles prof ON p.student_id = prof.id
WHERE p.paid_amount < p.total_amount
  AND p.payment_status != 'cancelled'
GROUP BY p.student_id, prof.name, prof.phone;

CREATE UNIQUE INDEX idx_mv_student_unpaid_student ON mv_student_unpaid_summary(student_id);

-- 2. ì¼ë³„ ë§¤ì¶œ ì§‘ê³„
CREATE MATERIALIZED VIEW mv_daily_sales AS
SELECT
  DATE(pt.paid_at) as sale_date,
  COUNT(DISTINCT pt.invoice_id) as invoice_count,
  COUNT(pt.id) as transaction_count,
  SUM(pt.amount) as total_sales,
  SUM(pt.fee) as total_fees,
  SUM(pt.net_amount) as net_sales,
  SUM(CASE WHEN pt.payment_method = 'card' THEN pt.amount ELSE 0 END) as card_sales,
  SUM(CASE WHEN pt.payment_method = 'cash' THEN pt.amount ELSE 0 END) as cash_sales,
  SUM(CASE WHEN pt.card_company = 'ì‹ í•œ' THEN pt.amount ELSE 0 END) as shinhan_sales,
  SUM(CASE WHEN pt.card_company = 'êµ­ë¯¼' THEN pt.amount ELSE 0 END) as kb_sales,
  SUM(CASE WHEN pt.card_company = 'ì‚¼ì„±' THEN pt.amount ELSE 0 END) as samsung_sales
FROM payment_transactions pt
WHERE pt.status = 'completed'
GROUP BY DATE(pt.paid_at);

CREATE UNIQUE INDEX idx_mv_daily_sales_date ON mv_daily_sales(sale_date);

-- 3. ì›”ë³„ ì²­êµ¬ì„œ í˜„í™©
CREATE MATERIALIZED VIEW mv_monthly_invoice_summary AS
SELECT
  DATE_TRUNC('month', i.created_at) as month,
  COUNT(CASE WHEN i.status IN ('sent', 'paid', 'partial', 'overdue') THEN 1 END) as sent_count,
  SUM(CASE WHEN i.status IN ('sent', 'paid', 'partial', 'overdue') THEN i.final_amount ELSE 0 END) as sent_amount,
  COUNT(CASE WHEN i.status = 'paid' THEN 1 END) as paid_count,
  SUM(CASE WHEN i.status = 'paid' THEN i.paid_amount ELSE 0 END) as paid_amount,
  COUNT(CASE WHEN i.status IN ('sent', 'partial', 'overdue') THEN 1 END) as unpaid_count,
  SUM(CASE WHEN i.status IN ('sent', 'partial', 'overdue') THEN (i.final_amount - i.paid_amount) ELSE 0 END) as unpaid_amount
FROM invoices i
GROUP BY DATE_TRUNC('month', i.created_at);

CREATE UNIQUE INDEX idx_mv_monthly_invoice_month ON mv_monthly_invoice_summary(month);

-- ===== Materialized View ìë™ ê°±ì‹  =====

-- ë§¤ì¼ ìƒˆë²½ 3ì‹œ ê°±ì‹ 
CREATE EXTENSION IF NOT EXISTS pg_cron;

SELECT cron.schedule(
  'refresh-mv-daily-sales',
  '0 3 * * *',  -- ë§¤ì¼ 03:00
  $$REFRESH MATERIALIZED VIEW CONCURRENTLY mv_daily_sales$$
);

SELECT cron.schedule(
  'refresh-mv-monthly-invoice',
  '0 3 1 * *',  -- ë§¤ì›” 1ì¼ 03:00
  $$REFRESH MATERIALIZED VIEW CONCURRENTLY mv_monthly_invoice_summary$$
);

-- ë¯¸ìˆ˜ê¸ˆì€ 1ì‹œê°„ë§ˆë‹¤ ê°±ì‹ 
SELECT cron.schedule(
  'refresh-mv-student-unpaid',
  '0 * * * *',  -- ë§¤ì‹œê°„
  $$REFRESH MATERIALIZED VIEW CONCURRENTLY mv_student_unpaid_summary$$
);
```

#### 4ï¸âƒ£ ìë™ ì •ë¦¬ (TTL)

```sql
-- ===== ë§Œë£Œëœ ì•Œë¦¼ ìë™ ì‚­ì œ =====

-- ë§¤ì¼ ìƒˆë²½ 2ì‹œ ì‹¤í–‰
SELECT cron.schedule(
  'cleanup-expired-notifications',
  '0 2 * * *',
  $$
    DELETE FROM notifications
    WHERE expires_at < NOW()
      AND status IN ('delivered', 'failed');
  $$
);

-- ===== ì˜¤ë˜ëœ ê²°ì œ íŠ¸ëœì­ì…˜ ì•„ì¹´ì´ë¸Œ =====

-- 1ë…„ ì´ìƒ ëœ íŠ¸ëœì­ì…˜ì„ ClickHouseë¡œ ì´ë™ (ì„ íƒ)
SELECT cron.schedule(
  'archive-old-transactions',
  '0 4 1 * *',  -- ë§¤ì›” 1ì¼ 04:00
  $$
    -- ClickHouseë¡œ ë³µì‚¬ í›„ ì‚­ì œ
    WITH archived AS (
      SELECT * FROM payment_transactions
      WHERE paid_at < NOW() - INTERVAL '1 year'
    )
    DELETE FROM payment_transactions
    WHERE id IN (SELECT id FROM archived);
  $$
);
```

---

### Phase 2: ì¤‘ê¸‰ ìµœì í™” (10K â†’ 100K) - Month 3-6

#### 1ï¸âƒ£ ì—°ê²° í’€ë§ (Connection Pooling)

```python
# FastAPIì— PgBouncer ì—°ë™

from sqlalchemy import create_engine
from sqlalchemy.pool import QueuePool

# Supabase Pooler URL ì‚¬ìš©
SUPABASE_POOLER_URL = "postgresql://postgres.pphzvnaedmzcvpxjulti:password@aws-0-ap-northeast-2.pooler.supabase.com:6543/postgres"

engine = create_engine(
    SUPABASE_POOLER_URL,
    poolclass=QueuePool,
    pool_size=20,          # ê¸°ë³¸ ì—°ê²° ìˆ˜
    max_overflow=10,       # ìµœëŒ€ ì¶”ê°€ ì—°ê²°
    pool_timeout=30,       # ì—°ê²° ëŒ€ê¸° ì‹œê°„
    pool_recycle=3600,     # 1ì‹œê°„ë§ˆë‹¤ ì¬ìƒì„±
    pool_pre_ping=True     # ì—°ê²° ì²´í¬
)
```

#### 2ï¸âƒ£ ìºì‹± ì „ëµ (Redis)

```python
# Redis ìºì‹± ì¶”ê°€

import redis
from functools import wraps
import json

redis_client = redis.Redis(
    host='redis-supabase.ap-northeast-2.cache.amazonaws.com',
    port=6379,
    db=0,
    decode_responses=True
)

def cache_result(ttl=300):
    """ê²°ê³¼ë¥¼ Redisì— ìºì‹± (ê¸°ë³¸ 5ë¶„)"""
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ìºì‹œ í‚¤ ìƒì„±
            cache_key = f"{func.__name__}:{str(args)}:{str(kwargs)}"

            # ìºì‹œ í™•ì¸
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # ìºì‹œ ì—†ìœ¼ë©´ ì‹¤í–‰
            result = await func(*args, **kwargs)

            # ê²°ê³¼ ìºì‹±
            redis_client.setex(cache_key, ttl, json.dumps(result))

            return result
        return wrapper
    return decorator

# ì‚¬ìš© ì˜ˆì‹œ
@app.get("/profiles/{profile_id}")
@cache_result(ttl=600)  # 10ë¶„ ìºì‹±
async def get_profile(profile_id: str):
    return supabase.table('profiles').select('*').eq('id', profile_id).execute()

@app.get("/stats/dashboard")
@cache_result(ttl=300)  # 5ë¶„ ìºì‹±
async def get_dashboard():
    # Materialized View ì¡°íšŒ (ì´ë¯¸ ì§‘ê³„ëœ ë°ì´í„°)
    return supabase.table('mv_daily_sales').select('*').limit(30).execute()
```

#### 3ï¸âƒ£ íŒŒí‹°ì…”ë‹ (Partitioning)

```sql
-- ===== payment_transactions íŒŒí‹°ì…”ë‹ (ì›”ë³„) =====

-- ê¸°ì¡´ í…Œì´ë¸”ì„ íŒŒí‹°ì…˜ í…Œì´ë¸”ë¡œ ë³€í™˜
-- ì£¼ì˜: í”„ë¡œë•ì…˜ì—ì„œëŠ” ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜ í•„ìš”

-- 1. ìƒˆ íŒŒí‹°ì…˜ í…Œì´ë¸” ìƒì„±
CREATE TABLE payment_transactions_partitioned (
  LIKE payment_transactions INCLUDING ALL
) PARTITION BY RANGE (paid_at);

-- 2. ì›”ë³„ íŒŒí‹°ì…˜ ìë™ ìƒì„± í•¨ìˆ˜
CREATE OR REPLACE FUNCTION create_monthly_partition(table_name TEXT, start_date DATE)
RETURNS VOID AS $$
DECLARE
  partition_name TEXT;
  start_ts TIMESTAMPTZ;
  end_ts TIMESTAMPTZ;
BEGIN
  partition_name := table_name || '_' || TO_CHAR(start_date, 'YYYY_MM');
  start_ts := start_date::TIMESTAMPTZ;
  end_ts := (start_date + INTERVAL '1 month')::TIMESTAMPTZ;

  EXECUTE format(
    'CREATE TABLE IF NOT EXISTS %I PARTITION OF %I FOR VALUES FROM (%L) TO (%L)',
    partition_name, table_name, start_ts, end_ts
  );
END;
$$ LANGUAGE plpgsql;

-- 3. í–¥í›„ 12ê°œì›” íŒŒí‹°ì…˜ ë¯¸ë¦¬ ìƒì„±
DO $$
DECLARE
  i INTEGER;
BEGIN
  FOR i IN 0..11 LOOP
    PERFORM create_monthly_partition(
      'payment_transactions_partitioned',
      DATE_TRUNC('month', NOW() + (i || ' months')::INTERVAL)::DATE
    );
  END LOOP;
END $$;

-- 4. ë§¤ì›” ìë™ìœ¼ë¡œ ë‹¤ìŒ ë‹¬ íŒŒí‹°ì…˜ ìƒì„±
SELECT cron.schedule(
  'create-next-month-partition',
  '0 0 1 * *',  -- ë§¤ì›” 1ì¼ 00:00
  $$
    SELECT create_monthly_partition(
      'payment_transactions_partitioned',
      DATE_TRUNC('month', NOW() + INTERVAL '12 months')::DATE
    );
  $$
);
```

#### 4ï¸âƒ£ ì¿¼ë¦¬ ë³‘ë ¬ ì²˜ë¦¬

```python
# FastAPIì—ì„œ ë³‘ë ¬ ì¿¼ë¦¬

import asyncio

@app.get("/dashboard/summary")
async def get_dashboard_summary():
    """ì—¬ëŸ¬ í†µê³„ë¥¼ ë³‘ë ¬ë¡œ ì¡°íšŒ"""

    async def get_student_count():
        return supabase.table('profiles').select('id', count='exact').eq('type', 'student').execute()

    async def get_unpaid_summary():
        return supabase.table('mv_student_unpaid_summary').select('*').execute()

    async def get_daily_sales():
        return supabase.table('mv_daily_sales').select('*').order('sale_date', desc=True).limit(7).execute()

    async def get_monthly_invoices():
        return supabase.table('mv_monthly_invoice_summary').select('*').order('month', desc=True).limit(3).execute()

    # ë³‘ë ¬ ì‹¤í–‰
    results = await asyncio.gather(
        get_student_count(),
        get_unpaid_summary(),
        get_daily_sales(),
        get_monthly_invoices()
    )

    return {
        'student_count': results[0].count,
        'unpaid_summary': results[1].data,
        'daily_sales': results[2].data,
        'monthly_invoices': results[3].data
    }
```

---

### Phase 3: ê³ ê¸‰ ìµœì í™” (100K â†’ 1M) - Month 6-12

#### 1ï¸âƒ£ Read Replica (ì½ê¸° ì „ìš© ë³µì œë³¸)

```python
# Supabase Read Replica í™œìš©

from supabase import create_client

# Write (Primary)
supabase_write = create_client(
    "https://pphzvnaedmzcvpxjulti.supabase.co",
    SUPABASE_SERVICE_KEY
)

# Read (Replica) - ì¡°íšŒ ì „ìš©
supabase_read = create_client(
    "https://pphzvnaedmzcvpxjulti-read.supabase.co",  # Read Replica URL
    SUPABASE_SERVICE_KEY
)

# ì‚¬ìš© ë¶„ë¦¬
@app.get("/profiles")
async def get_profiles():
    # ì¡°íšŒëŠ” Read Replica
    return supabase_read.table('profiles').select('*').execute()

@app.post("/profiles")
async def create_profile(data: dict):
    # ì“°ê¸°ëŠ” Primary
    return supabase_write.table('profiles').insert(data).execute()
```

#### 2ï¸âƒ£ Full-Text Search (ì „ë¬¸ ê²€ìƒ‰)

```sql
-- ===== profiles í…Œì´ë¸”ì— ì „ë¬¸ ê²€ìƒ‰ ì¶”ê°€ =====

-- 1. tsvector ì»¬ëŸ¼ ì¶”ê°€
ALTER TABLE profiles ADD COLUMN search_vector tsvector;

-- 2. ê²€ìƒ‰ ë²¡í„° ìƒì„± í•¨ìˆ˜
CREATE OR REPLACE FUNCTION profiles_search_vector_update()
RETURNS TRIGGER AS $$
BEGIN
  NEW.search_vector :=
    setweight(to_tsvector('simple', COALESCE(NEW.name, '')), 'A') ||
    setweight(to_tsvector('simple', COALESCE(NEW.phone, '')), 'B') ||
    setweight(to_tsvector('simple', COALESCE(NEW.email, '')), 'B') ||
    setweight(to_tsvector('simple', COALESCE(NEW.metadata::text, '')), 'C');
  RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- 3. íŠ¸ë¦¬ê±° ìƒì„±
CREATE TRIGGER profiles_search_vector_trigger
  BEFORE INSERT OR UPDATE ON profiles
  FOR EACH ROW
  EXECUTE FUNCTION profiles_search_vector_update();

-- 4. ê¸°ì¡´ ë°ì´í„° ì—…ë°ì´íŠ¸
UPDATE profiles SET search_vector = NULL;  -- íŠ¸ë¦¬ê±° ì‹¤í–‰

-- 5. GIN ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_profiles_search ON profiles USING GIN(search_vector);

-- 6. ê²€ìƒ‰ ì¿¼ë¦¬
SELECT * FROM profiles
WHERE search_vector @@ to_tsquery('simple', 'ê¹€ì² ìˆ˜ | 010-1234-5678')
ORDER BY ts_rank(search_vector, to_tsquery('simple', 'ê¹€ì² ìˆ˜')) DESC;
```

#### 3ï¸âƒ£ ë°ì´í„°ë² ì´ìŠ¤ ìƒ¤ë”© (Sharding)

```sql
-- ===== í•™ìƒ ID ê¸°ë°˜ ìƒ¤ë”© ì¤€ë¹„ =====

-- ìƒ¤ë“œ í‚¤ í•¨ìˆ˜ (í•´ì‹œ ê¸°ë°˜)
CREATE OR REPLACE FUNCTION get_shard_id(student_id UUID, num_shards INTEGER DEFAULT 10)
RETURNS INTEGER AS $$
BEGIN
  RETURN (hashtext(student_id::text) % num_shards);
END;
$$ LANGUAGE plpgsql IMMUTABLE;

-- ìƒ¤ë“œë³„ ë¼ìš°íŒ… í…Œì´ë¸”
CREATE TABLE shard_routing (
  shard_id INTEGER PRIMARY KEY,
  db_host TEXT NOT NULL,
  db_port INTEGER DEFAULT 5432,
  db_name TEXT NOT NULL,
  is_active BOOLEAN DEFAULT true,
  created_at TIMESTAMPTZ DEFAULT now()
);

-- ìƒ¤ë“œ ì •ë³´ ì…ë ¥ (ì˜ˆì‹œ)
INSERT INTO shard_routing (shard_id, db_host, db_name) VALUES
  (0, 'shard-0.supabase.co', 'postgres'),
  (1, 'shard-1.supabase.co', 'postgres'),
  (2, 'shard-2.supabase.co', 'postgres');
```

```python
# FastAPIì—ì„œ ìƒ¤ë”© ë¼ìš°íŒ…

from typing import Dict
from supabase import create_client

class ShardManager:
    def __init__(self):
        self.shards: Dict[int, Client] = {}
        self._load_shards()

    def _load_shards(self):
        """ìƒ¤ë“œ ì •ë³´ ë¡œë“œ"""
        # ì‹¤ì œë¡œëŠ” shard_routing í…Œì´ë¸”ì—ì„œ ì¡°íšŒ
        self.shards = {
            0: create_client("https://shard-0.supabase.co", key),
            1: create_client("https://shard-1.supabase.co", key),
            2: create_client("https://shard-2.supabase.co", key),
        }

    def get_shard(self, student_id: str) -> Client:
        """í•™ìƒ IDë¡œ ìƒ¤ë“œ ê²°ì •"""
        # í•´ì‹œ ê¸°ë°˜ ìƒ¤ë”©
        shard_id = hash(student_id) % len(self.shards)
        return self.shards[shard_id]

shard_manager = ShardManager()

@app.get("/profiles/{student_id}")
async def get_student(student_id: str):
    # ì˜¬ë°”ë¥¸ ìƒ¤ë“œë¡œ ë¼ìš°íŒ…
    shard = shard_manager.get_shard(student_id)
    return shard.table('profiles').select('*').eq('id', student_id).execute()
```

#### 4ï¸âƒ£ CDC (Change Data Capture) â†’ ClickHouse

```sql
-- ===== Supabase Realtimeìœ¼ë¡œ ë³€ê²½ ê°ì§€ â†’ ClickHouse ì „ì†¡ =====

-- 1. í…Œì´ë¸”ë³„ Realtime í™œì„±í™”
ALTER PUBLICATION supabase_realtime ADD TABLE payment_transactions;
ALTER PUBLICATION supabase_realtime ADD TABLE invoices;
ALTER PUBLICATION supabase_realtime ADD TABLE bookings;

-- 2. FastAPIì—ì„œ Realtime êµ¬ë…
```

```python
# FastAPIì—ì„œ Realtime êµ¬ë… â†’ ClickHouse ì „ì†¡

from supabase import create_client, RealtimeChannel
from clickhouse_driver import Client

clickhouse = Client(host='clickhouse.autus.io')
supabase = create_client(SUPABASE_URL, SUPABASE_KEY)

def on_payment_insert(payload):
    """ê²°ì œ íŠ¸ëœì­ì…˜ ë°œìƒ ì‹œ ClickHouseì— ì´ë²¤íŠ¸ ë¡œê¹…"""
    data = payload['new']

    clickhouse.execute(
        'INSERT INTO events (event_type, entity_id, metadata, created_at) VALUES',
        [{
            'event_type': 'payment.completed',
            'entity_id': data['id'],
            'metadata': json.dumps(data),
            'created_at': datetime.now()
        }]
    )

# Realtime êµ¬ë…
channel: RealtimeChannel = supabase.channel('payment-events')
channel.on_postgres_changes(
    event='INSERT',
    schema='public',
    table='payment_transactions',
    callback=on_payment_insert
).subscribe()
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§ ë° ì•ŒëŒ

### 1ï¸âƒ£ Supabase Dashboard ë©”íŠ¸ë¦­

```sql
-- ëŠë¦° ì¿¼ë¦¬ ê°ì§€
SELECT
  query,
  calls,
  total_time,
  mean_time,
  max_time
FROM pg_stat_statements
WHERE mean_time > 100  -- 100ms ì´ìƒ
ORDER BY mean_time DESC
LIMIT 20;

-- í…Œì´ë¸” í¬ê¸° ëª¨ë‹ˆí„°ë§
SELECT
  schemaname,
  tablename,
  pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) AS size,
  pg_total_relation_size(schemaname||'.'||tablename) AS size_bytes
FROM pg_tables
WHERE schemaname = 'public'
ORDER BY size_bytes DESC;

-- ì¸ë±ìŠ¤ ì‚¬ìš©ë¥ 
SELECT
  schemaname,
  tablename,
  indexname,
  idx_scan as index_scans,
  idx_tup_read as tuples_read,
  idx_tup_fetch as tuples_fetched
FROM pg_stat_user_indexes
WHERE idx_scan < 100  -- ê±°ì˜ ì‚¬ìš© ì•ˆ ë˜ëŠ” ì¸ë±ìŠ¤
ORDER BY idx_scan;
```

### 2ï¸âƒ£ ì„±ëŠ¥ ì•ŒëŒ (FastAPI)

```python
# ëŠë¦° ì¿¼ë¦¬ ë¡œê¹…

import time
from fastapi import Request

@app.middleware("http")
async def log_slow_requests(request: Request, call_next):
    start_time = time.time()

    response = await call_next(request)

    duration = time.time() - start_time

    # 500ms ì´ìƒ ê±¸ë¦° ìš”ì²­ ë¡œê¹…
    if duration > 0.5:
        logger.warning(
            f"Slow request: {request.method} {request.url.path} - {duration:.2f}s"
        )

        # ëª°íŠ¸ë´‡ìœ¼ë¡œ ì•Œë¦¼
        await send_telegram_alert(
            f"âš ï¸ Slow API: {request.url.path} ({duration:.2f}s)"
        )

    return response
```

---

## ğŸ’° ê·œëª¨ë³„ ì¸í”„ë¼ ë¹„ìš©

| ê·œëª¨ | Supabase | Redis | Read Replica | ClickHouse | í•©ê³„/ì›” |
|------|----------|-------|--------------|------------|---------|
| **3K** | Free | - | - | - | **ë¬´ë£Œ** |
| **10K** | $25 | $20 | - | - | **$45** |
| **100K** | $125 | $50 | $125 | $100 | **$400** |
| **1M** | $750 | $200 | $750 | $500 | **$2,200** |

---

## âœ… ì‹¤í–‰ ì²´í¬ë¦¬ìŠ¤íŠ¸

### Week 2-3 (Phase 1)
- [ ] ì¸ë±ìŠ¤ 30ê°œ ìƒì„±
- [ ] RLS ì •ì±… 5ê°œ í…Œì´ë¸” ì ìš©
- [ ] Materialized View 3ê°œ ìƒì„±
- [ ] pg_cron ìë™í™” 4ê°œ ì„¤ì •
- [ ] TTL ì •ë¦¬ ì‘ì—… 2ê°œ ì„¤ì •

### Month 3-6 (Phase 2)
- [ ] PgBouncer ì—°ê²° í’€ë§
- [ ] Redis ìºì‹± (10ë¶„ TTL)
- [ ] íŒŒí‹°ì…”ë‹ (payment_transactions)
- [ ] ë³‘ë ¬ ì¿¼ë¦¬ ì ìš©

### Month 6-12 (Phase 3)
- [ ] Read Replica ì„¤ì •
- [ ] Full-Text Search êµ¬í˜„
- [ ] ìƒ¤ë”© ì¤€ë¹„ (10 shards)
- [ ] CDC â†’ ClickHouse ì—°ë™

---

**ğŸ¯ í•µì‹¬**: ìµœì í™”ëŠ” ë‹¨ê³„ì ìœ¼ë¡œ ì§„í–‰. Phase 1ë§Œìœ¼ë¡œë„ 10ë§Œëª…ê¹Œì§€ ì¶©ë¶„íˆ ëŒ€ì‘ ê°€ëŠ¥í•©ë‹ˆë‹¤.
