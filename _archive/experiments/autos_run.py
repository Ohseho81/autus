#!/usr/bin/env python3
"""
AUTUS 2.0 Data Pipeline Runner
==============================
ì˜ì‚¬ê²°ì • OS - Raw Dataì—ì„œ 7ëŒ€ ë…¸ì´ì¦ˆ ì§€í‘œ ì¶”ì¶œ ë° HUD ì¶œë ¥

Usage:
    # í†µí•© ë¶„ì„ (7ëŒ€ ë…¸ì´ì¦ˆ)
    python3 autos_run.py --task integrated_analysis --input "ë²•ì¸ ë¶€ì±„ 5ì–µ ìƒí™˜ vs ì‹ ê·œ ì‚¬ì—… 3ì–µ íˆ¬ì…"
    
    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸
    python3 autos_run.py --flow email_to_sheets --mock_data "2025-12-22, ì‹ í•œì€í–‰, 5,500,000ì› ì…ê¸ˆ"
"""

import os
import sys
import json
import argparse
import re
from datetime import datetime
from dataclasses import dataclass, asdict
from typing import List, Dict, Optional
from enum import Enum

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7-LAYER ARCHITECTURE INTEGRATION
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Layer(Enum):
    L0_EXTERNAL = 0      # ì™¸ë¶€ ë°ì´í„° ìˆ˜ì‹ 
    L1_SYSTEM = 1        # ì‹œìŠ¤í…œ ìƒíƒœ
    L2_ENTITY = 2        # ë°ì´í„° ì—”í‹°í‹°
    L3_CANVAS = 3        # ì²˜ë¦¬ ë¡œì§
    L4_DOCK = 4          # ì•¡ì…˜ ë””ìŠ¤íŒ¨ì¹˜
    L5_OVERLAY = 5       # ì•Œë¦¼/ë¡œê·¸
    L6_OVERRIDE = 6      # ê¸´ê¸‰ ì²˜ë¦¬

class EdgePolicy(Enum):
    NORMAL = "NORMAL"           # ì¼ë°˜ ì²˜ë¦¬
    ALTERNATE = "ALTERNATE"     # ëŒ€ì²´ ê²½ë¡œ
    LOOP = "LOOP"               # ë°˜ë³µ ì²˜ë¦¬

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# DATA MODELS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class FinanceRecord:
    """ì¬ë¬´ ë°ì´í„° ë ˆì½”ë“œ"""
    id: str
    date: str
    bank: str
    amount: float
    type: str  # ì…ê¸ˆ/ì¶œê¸ˆ
    description: str
    category: Optional[str] = None
    tax_code: Optional[str] = None
    processed: bool = False
    layer: int = 0
    policy: str = "NORMAL"

@dataclass
class PipelineResult:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ê²°ê³¼"""
    success: bool
    flow: str
    records_processed: int
    records_failed: int
    duration_ms: float
    output_path: Optional[str] = None
    errors: List[str] = None
    ledger: List[Dict] = None

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# LEDGER (Decision Memory)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class DecisionLedger:
    """ê²°ì • ê¸°ë¡ ì›ì¥"""
    
    def __init__(self):
        self.entries = []
    
    def record(self, layer: Layer, action: str, data: Dict, policy: EdgePolicy = EdgePolicy.NORMAL):
        entry = {
            "timestamp": datetime.now().isoformat(),
            "layer": layer.name,
            "action": action,
            "policy": policy.value,
            "data": data
        }
        self.entries.append(entry)
        self._print_entry(entry)
    
    def _print_entry(self, entry):
        icons = {
            "L0_EXTERNAL": "ğŸŒ",
            "L1_SYSTEM": "âš™ï¸",
            "L2_ENTITY": "ğŸ“Š",
            "L3_CANVAS": "ğŸ¯",
            "L4_DOCK": "ğŸš€",
            "L5_OVERLAY": "ğŸ””",
            "L6_OVERRIDE": "âš ï¸"
        }
        icon = icons.get(entry["layer"], "â€¢")
        time = entry["timestamp"].split("T")[1][:8]
        print(f"  {icon} [{time}] {entry['layer']}: {entry['action']} ({entry['policy']})")
    
    def get_entries(self) -> List[Dict]:
        return self.entries

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PARSER (L0 â†’ L2)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FinanceParser:
    """ì¬ë¬´ ë°ì´í„° íŒŒì„œ"""
    
    def __init__(self, ledger: DecisionLedger):
        self.ledger = ledger
    
    def parse_email_data(self, raw_data: str) -> FinanceRecord:
        """ì´ë©”ì¼/í…ìŠ¤íŠ¸ ë°ì´í„° íŒŒì‹±"""
        self.ledger.record(Layer.L0_EXTERNAL, "receive_data", {"raw": raw_data[:50]})
        
        # íŒ¨í„´ ë§¤ì¹­
        patterns = {
            "date": r"(\d{4}-\d{2}-\d{2})",
            "amount": r"([\d,]+)ì›",
            "type": r"(ì…ê¸ˆ|ì¶œê¸ˆ|ì´ì²´)",
            "bank": r"(ì‹ í•œ|êµ­ë¯¼|ìš°ë¦¬|í•˜ë‚˜|ê¸°ì—…|ë†í˜‘|SC|ì”¨í‹°)ì€í–‰?"
        }
        
        result = {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "amount": 0,
            "type": "ì…ê¸ˆ",
            "bank": "Unknown",
            "description": raw_data
        }
        
        for key, pattern in patterns.items():
            match = re.search(pattern, raw_data)
            if match:
                value = match.group(1)
                if key == "amount":
                    value = float(value.replace(",", ""))
                result[key] = value
        
        self.ledger.record(Layer.L2_ENTITY, "parse_complete", result)
        
        record = FinanceRecord(
            id=f"FIN-{datetime.now().strftime('%Y%m%d%H%M%S')}",
            date=result["date"],
            bank=result["bank"],
            amount=result["amount"],
            type=result["type"],
            description=result["description"],
            layer=2,
            policy="NORMAL"
        )
        
        return record

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CLASSIFIER (L3)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class FinanceClassifier:
    """ì¬ë¬´ ë°ì´í„° ë¶„ë¥˜ê¸°"""
    
    CATEGORIES = {
        "ê¸‰ì—¬": ["ê¸‰ì—¬", "ì›”ê¸‰", "ìƒì—¬", "ë³´ë„ˆìŠ¤"],
        "ë§¤ì¶œ": ["ê²°ì œ", "íŒë§¤", "ìˆ˜ìµ", "ë§¤ì¶œ"],
        "ë¹„ìš©": ["ì§€ì¶œ", "êµ¬ë§¤", "ê²°ì œ", "ë¹„ìš©"],
        "ì„¸ê¸ˆ": ["ì„¸ê¸ˆ", "ë¶€ê°€ì„¸", "ì›ì²œì„¸", "ë²•ì¸ì„¸"],
        "ëŒ€ì¶œ": ["ëŒ€ì¶œ", "ì´ì", "ìƒí™˜"],
        "íˆ¬ì": ["íˆ¬ì", "ë°°ë‹¹", "ì£¼ì‹"],
    }
    
    TAX_CODES = {
        "ê¸‰ì—¬": "T-SAL",
        "ë§¤ì¶œ": "T-REV",
        "ë¹„ìš©": "T-EXP",
        "ì„¸ê¸ˆ": "T-TAX",
        "ëŒ€ì¶œ": "T-LOA",
        "íˆ¬ì": "T-INV",
    }
    
    def __init__(self, ledger: DecisionLedger):
        self.ledger = ledger
    
    def classify(self, record: FinanceRecord) -> FinanceRecord:
        """ë ˆì½”ë“œ ë¶„ë¥˜ ë° ì„¸ê¸ˆ ì½”ë“œ í• ë‹¹"""
        self.ledger.record(Layer.L3_CANVAS, "classify_start", {"id": record.id})
        
        description = record.description.lower()
        
        for category, keywords in self.CATEGORIES.items():
            if any(kw in description for kw in keywords):
                record.category = category
                record.tax_code = self.TAX_CODES.get(category, "T-UNK")
                break
        
        if not record.category:
            record.category = "ê¸°íƒ€"
            record.tax_code = "T-ETC"
        
        # ê¸ˆì•¡ì— ë”°ë¥¸ ì •ì±… ê²°ì •
        if record.amount >= 10_000_000:  # 1ì²œë§Œì› ì´ìƒ
            record.policy = "ALTERNATE"
            self.ledger.record(Layer.L6_OVERRIDE, "high_value_alert", 
                             {"amount": record.amount}, EdgePolicy.ALTERNATE)
        elif record.category == "ì„¸ê¸ˆ":
            record.policy = "LOOP"
            self.ledger.record(Layer.L3_CANVAS, "tax_item_loop", 
                             {"category": record.category}, EdgePolicy.LOOP)
        
        record.layer = 3
        self.ledger.record(Layer.L3_CANVAS, "classify_complete", 
                          {"category": record.category, "tax_code": record.tax_code})
        
        return record

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# SHEET WRITER (L4)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class SheetWriter:
    """Google Sheets ê¸°ë¡ê¸° (Mock)"""
    
    def __init__(self, ledger: DecisionLedger):
        self.ledger = ledger
        self.mock_data = []
    
    def write(self, record: FinanceRecord) -> bool:
        """ì‹œíŠ¸ì— ê¸°ë¡ (Mock)"""
        self.ledger.record(Layer.L4_DOCK, "write_start", {"id": record.id})
        
        try:
            row = {
                "ID": record.id,
                "ë‚ ì§œ": record.date,
                "ì€í–‰": record.bank,
                "ê¸ˆì•¡": record.amount,
                "ìœ í˜•": record.type,
                "ì¹´í…Œê³ ë¦¬": record.category,
                "ì„¸ê¸ˆì½”ë“œ": record.tax_code,
                "ì„¤ëª…": record.description[:50],
                "ì •ì±…": record.policy
            }
            
            self.mock_data.append(row)
            record.processed = True
            record.layer = 4
            
            self.ledger.record(Layer.L4_DOCK, "write_complete", {"row": len(self.mock_data)})
            self.ledger.record(Layer.L5_OVERLAY, "notification", 
                             {"message": f"Record {record.id} saved"})
            
            return True
            
        except Exception as e:
            self.ledger.record(Layer.L6_OVERRIDE, "write_error", 
                             {"error": str(e)}, EdgePolicy.ALTERNATE)
            return False
    
    def get_mock_data(self) -> List[Dict]:
        return self.mock_data

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# PIPELINE RUNNER
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class PipelineRunner:
    """íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ê¸°"""
    
    def __init__(self):
        self.ledger = DecisionLedger()
        self.parser = FinanceParser(self.ledger)
        self.classifier = FinanceClassifier(self.ledger)
        self.writer = SheetWriter(self.ledger)
    
    def run_email_to_sheets(self, mock_data: str) -> PipelineResult:
        """ì´ë©”ì¼ â†’ ì‹œíŠ¸ íŒŒì´í”„ë¼ì¸"""
        start_time = datetime.now()
        
        print("\n" + "â•" * 60)
        print("ğŸš€ AUTUS Pipeline: email_to_sheets")
        print("â•" * 60)
        print(f"ğŸ“§ Input: {mock_data[:60]}...")
        print("â”€" * 60)
        print("\nğŸ“‹ Processing Ledger:")
        
        self.ledger.record(Layer.L1_SYSTEM, "pipeline_start", {"flow": "email_to_sheets"})
        
        records_processed = 0
        records_failed = 0
        errors = []
        
        try:
            # L0 â†’ L2: Parse
            record = self.parser.parse_email_data(mock_data)
            
            # L3: Classify
            record = self.classifier.classify(record)
            
            # L4: Write
            success = self.writer.write(record)
            
            if success:
                records_processed += 1
            else:
                records_failed += 1
                errors.append(f"Failed to write record {record.id}")
            
            self.ledger.record(Layer.L1_SYSTEM, "pipeline_complete", 
                             {"processed": records_processed, "failed": records_failed})
            
        except Exception as e:
            records_failed += 1
            errors.append(str(e))
            self.ledger.record(Layer.L6_OVERRIDE, "pipeline_error", 
                             {"error": str(e)}, EdgePolicy.ALTERNATE)
        
        duration = (datetime.now() - start_time).total_seconds() * 1000
        
        result = PipelineResult(
            success=records_failed == 0,
            flow="email_to_sheets",
            records_processed=records_processed,
            records_failed=records_failed,
            duration_ms=duration,
            errors=errors if errors else None,
            ledger=self.ledger.get_entries()
        )
        
        self._print_result(result)
        self._print_mock_sheet()
        
        return result
    
    def _print_result(self, result: PipelineResult):
        print("\n" + "â”€" * 60)
        print("ğŸ“Š Result Summary:")
        print(f"  â€¢ Status: {'âœ… Success' if result.success else 'âŒ Failed'}")
        print(f"  â€¢ Processed: {result.records_processed}")
        print(f"  â€¢ Failed: {result.records_failed}")
        print(f"  â€¢ Duration: {result.duration_ms:.2f}ms")
        print(f"  â€¢ Ledger entries: {len(result.ledger)}")
        
        if result.errors:
            print("\n  âŒ Errors:")
            for error in result.errors:
                print(f"     â€¢ {error}")
    
    def _print_mock_sheet(self):
        data = self.writer.get_mock_data()
        if data:
            print("\n" + "â”€" * 60)
            print("ğŸ“ Mock Sheet Output:")
            print("â”€" * 60)
            for row in data:
                print(f"  ID: {row['ID']}")
                print(f"  ë‚ ì§œ: {row['ë‚ ì§œ']} | ì€í–‰: {row['ì€í–‰']}")
                print(f"  ê¸ˆì•¡: {row['ê¸ˆì•¡']:,.0f}ì› ({row['ìœ í˜•']})")
                print(f"  ì¹´í…Œê³ ë¦¬: {row['ì¹´í…Œê³ ë¦¬']} | ì„¸ê¸ˆì½”ë“œ: {row['ì„¸ê¸ˆì½”ë“œ']}")
                print(f"  ì •ì±…: {row['ì •ì±…']}")
                print()

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# INTEGRATED ANALYSIS (7ëŒ€ ë…¸ì´ì¦ˆ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_integrated_analysis(input_text: str, output_path: str = None):
    """
    í†µí•© ë¶„ì„: 7ëŒ€ ë…¸ì´ì¦ˆ ì§€í‘œ ì¶”ì¶œ ë° HUD ì¶œë ¥
    """
    from autus_distiller import Distiller
    from autus_hud import HUDRenderer
    
    print("\n" + "â•" * 70)
    print("ğŸ§  AUTUS 2.0 INTEGRATED ANALYSIS")
    print("â•" * 70)
    print(f"ğŸ“¥ Input: {input_text[:60]}...")
    print("â”€" * 70)
    
    # Distillerë¡œ 7ëŒ€ ë…¸ì´ì¦ˆ ì¶”ì¶œ
    distiller = Distiller()
    hud_result = distiller.distill(input_text)
    
    # HUD ìŠ¤íƒ€ì¼ ì¶œë ¥
    renderer = HUDRenderer()
    renderer.render(hud_result)
    
    # JSON ì €ì¥
    if output_path:
        json_output = distiller.to_hud_json(hud_result)
        os.makedirs(os.path.dirname(output_path) if os.path.dirname(output_path) else ".", exist_ok=True)
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"ğŸ’¾ JSON saved to: {output_path}")
    else:
        # ê¸°ë³¸ ì €ì¥ ê²½ë¡œ
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        default_path = f"./output/hud_{timestamp}.json"
        os.makedirs("./output", exist_ok=True)
        json_output = distiller.to_hud_json(hud_result)
        with open(default_path, 'w', encoding='utf-8') as f:
            f.write(json_output)
        print(f"ğŸ’¾ JSON saved to: {default_path}")
    
    return hud_result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    parser = argparse.ArgumentParser(
        description="AUTUS 2.0 Pipeline Runner",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  # í†µí•© ë¶„ì„ (7ëŒ€ ë…¸ì´ì¦ˆ)
  python3 autos_run.py --task integrated_analysis --input "ë²•ì¸ ë¶€ì±„ 5ì–µ ìƒí™˜ vs ì‹ ê·œ ì‚¬ì—… 3ì–µ íˆ¬ì…"
  
  # ì¬ë¬´ íŒŒì´í”„ë¼ì¸
  python3 autos_run.py --flow email_to_sheets --mock_data "2025-12-22, ì‹ í•œì€í–‰, 5,500,000ì› ì…ê¸ˆ"
        """
    )
    
    # ìƒˆë¡œìš´ í†µí•© ë¶„ì„ ì˜µì…˜
    parser.add_argument("--task", type=str,
                        choices=["integrated_analysis"],
                        help="Analysis task to run")
    parser.add_argument("--input", "-i", type=str,
                        help="Input text for analysis")
    
    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ì˜µì…˜
    parser.add_argument("--flow", type=str,
                        choices=["email_to_sheets", "parse_invoice", "monthly_report"],
                        help="Pipeline flow to execute")
    parser.add_argument("--mock_data", type=str,
                        help="Mock data string for testing")
    parser.add_argument("--file", type=str,
                        help="Input file path")
    parser.add_argument("--output", "-o", type=str,
                        help="Output file path")
    parser.add_argument("--verbose", "-v", action="store_true",
                        help="Verbose output")
    
    args = parser.parse_args()
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # í†µí•© ë¶„ì„ ëª¨ë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if args.task == "integrated_analysis":
        if not args.input:
            print("âŒ Error: --input is required for integrated_analysis")
            print("   Example: --input \"ë²•ì¸ ë¶€ì±„ 5ì–µ ìƒí™˜ vs ì‹ ê·œ ì‚¬ì—… 3ì–µ íˆ¬ì…\"")
            sys.exit(1)
        
        result = run_integrated_analysis(args.input, args.output)
        
        print("\n" + "â•" * 70)
        print(f"ğŸ Analysis completed | Dominant Noise: {result.dominant_noise}")
        print("â•" * 70)
        sys.exit(0)
    
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ ëª¨ë“œ
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    if not args.flow:
        parser.print_help()
        sys.exit(1)
    
    runner = PipelineRunner()
    
    if args.flow == "email_to_sheets":
        if not args.mock_data:
            args.mock_data = "2025-12-22, ì‹ í•œì€í–‰, 5,500,000ì› ì…ê¸ˆ, ì ìš”: ê±°ë˜ì²˜ ê²°ì œ"
        
        result = runner.run_email_to_sheets(args.mock_data)
        
    elif args.flow == "parse_invoice":
        print("ğŸ“„ Invoice parsing not yet implemented")
        sys.exit(1)
        
    elif args.flow == "monthly_report":
        print("ğŸ“Š Monthly report not yet implemented")
        sys.exit(1)
    
    print("\n" + "â•" * 60)
    print("ğŸ Pipeline execution completed")
    print("â•" * 60)
    
    sys.exit(0 if result.success else 1)


if __name__ == "__main__":
    main()
